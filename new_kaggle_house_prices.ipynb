{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9bc639",
   "metadata": {},
   "source": [
    "### Ячейка 1: Импорты и глобальные настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c136fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все библиотеки импортированы.\n",
      "Обучение будет производиться на устройстве: cuda\n",
      "Optuna version: 4.3.0\n",
      "MLflow version: 3.1.0\n"
     ]
    }
   ],
   "source": [
    "# --- Системные и основные библиотеки ---\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Визуализация ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "# --- Машинное обучение (Scikit-learn) ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Машинное обучение (PyTorch) ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# --- Инструменты для экспериментов ---\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# --- Игнорируем предупреждения для чистоты вывода ---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Константы ---\n",
    "DATA_PATH = \"data\"\n",
    "FILE_TRAIN = os.path.join(DATA_PATH, \"train.csv\")\n",
    "FILE_TEST = os.path.join(DATA_PATH, \"test.csv\")\n",
    "SUBMISSION_FILE = 'submission_house_prices.csv'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Настройки для визуализации ---\n",
    "plt.style.use('ggplot')\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "print(\"Все библиотеки импортированы.\")\n",
    "print(f\"Обучение будет производиться на устройстве: {DEVICE}\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "c70d60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Путь к Python, который использует ядро: /usr/bin/python\n",
      "Версия Optuna, видимая ядру: 4.3.0\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 0: Диагностика окружения\n",
    "import sys\n",
    "import optuna\n",
    "print(f\"Путь к Python, который использует ядро: {sys.executable}\")\n",
    "print(f\"Версия Optuna, видимая ядру: {optuna.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d74704",
   "metadata": {},
   "source": [
    "### Ячейка 2: Конфигурация эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "9ca0c8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Конфигурация эксперимента задана.\n",
      "Optuna проведет 200 экспериментов.\n"
     ]
    }
   ],
   "source": [
    "# --- Общие настройки эксперимента ---\n",
    "EXPERIMENT_NAME = \"House Prices - Optuna & MLflow\"\n",
    "N_TRIALS = 200 # Количество экспериментов для Optuna\n",
    "EPOCHS = 240  # Фиксированное количество эпох для каждого эксперимента\n",
    "\n",
    "# --- Базовые параметры (могут быть переопределены Optuna) ---\n",
    "class Config:\n",
    "    # Параметры DataLoader\n",
    "    BATCH_SIZE = 128\n",
    "    \n",
    "    # Параметры оптимизатора\n",
    "    LEARNING_RATE = 0.005\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    \n",
    "    # Параметры планировщика\n",
    "    SCHEDULER_PATIENCE = 30\n",
    "    SCHEDULER_FACTOR = 0.5\n",
    "    \n",
    "    # Параметры архитектуры модели\n",
    "    # Список с количеством нейронов в каждом скрытом слое\n",
    "    HIDDEN_LAYERS = [128, 64] \n",
    "    # Список со значением Dropout для каждого скрытого слоя\n",
    "    DROPOUT_RATES = [0.4, 0.4]\n",
    "\n",
    "print(\"Конфигурация эксперимента задана.\")\n",
    "print(f\"Optuna проведет {N_TRIALS} экспериментов.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b354111",
   "metadata": {},
   "source": [
    "### Ячейка 3: Комплексная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "e74be5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно загружены.\n",
      "Предобработка завершена.\n",
      "Размер обработанного train датасета: (1460, 124)\n",
      "Размер обработанного test датасета:  (1459, 124)\n",
      "Целевая переменная 'SalePrice' сохранена отдельно, размер: (1460,)\n"
     ]
    }
   ],
   "source": [
    "# --- ЗАГРУЗКА ДАННЫХ ---\n",
    "try:\n",
    "    df_train = pd.read_csv(FILE_TRAIN)\n",
    "    df_test = pd.read_csv(FILE_TEST)\n",
    "    df_test_original = df_test.copy()\n",
    "    print(\"Данные успешно загружены.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Ошибка: Файлы не найдены в директории '{DATA_PATH}'.\")\n",
    "\n",
    "# --- ПОЛНЫЙ ПАЙПЛАЙН ПРЕДОБРАБОТКИ ---\n",
    "\n",
    "# 1. Подготовка\n",
    "df_train_proc = df_train.copy()\n",
    "df_test_proc = df_test.copy()\n",
    "train_target = df_train_proc['SalePrice'].copy()\n",
    "df_train_proc.drop('SalePrice', axis=1, inplace=True)\n",
    "train_rows = len(df_train_proc)\n",
    "df_combined = pd.concat([df_train_proc, df_test_proc], ignore_index=True)\n",
    "\n",
    "\n",
    "# --- ЭТАП 2: БАЗОВАЯ ОЧИСТКА И ЗАПОЛНЕНИЕ ПРОПУСКОВ ---\n",
    "\n",
    "# 2.1 Рассчитываем медианы на ОБЪЕДИНЕННЫХ данных для большей точности\n",
    "lotfrontage_median = df_combined['LotFrontage'].median()\n",
    "garageyrblt_median = df_combined['GarageYrBlt'].median()\n",
    "\n",
    "# 2.2 Заполняем пропуски\n",
    "df_combined['LotFrontage'].fillna(lotfrontage_median, inplace=True)\n",
    "df_combined['GarageYrBlt'].fillna(garageyrblt_median, inplace=True)\n",
    "\n",
    "# 2.3 Заполняем нулями столбцы, где NA означает \"отсутствие\" объекта\n",
    "cols_fill_zero = [\n",
    "    'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "    'GarageCars', 'GarageArea', 'BsmtFullBath', 'BsmtHalfBath'\n",
    "]\n",
    "for col in cols_fill_zero:\n",
    "    df_combined[col].fillna(0, inplace=True)\n",
    "\n",
    "# 2.4 Заполняем пропуски в категориальных признаках строкой 'NA'\n",
    "cat_cols_fill_na = [\n",
    "    'Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "    'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "    'PoolQC', 'Fence', 'MiscFeature', 'MasVnrType', 'Electrical', 'MSZoning',\n",
    "    'Utilities', 'Exterior1st', 'Exterior2nd', 'KitchenQual', 'Functional', 'SaleType'\n",
    "]\n",
    "for col in cat_cols_fill_na:\n",
    "    df_combined[col].fillna('NA', inplace=True)\n",
    "\n",
    "# 2.5 Исправляем опечатки, замеченные при анализе данных\n",
    "df_combined['Exterior2nd'].replace({\"CmentBd\": \"CemntBd\", \"Wd Shng\": \"WdShing\"}, inplace=True)\n",
    "\n",
    "\n",
    "# --- ЭТАП 3: ИНЖИНИРИНГ ПРИЗНАКОВ (FEATURE ENGINEERING) ---\n",
    "\n",
    "# 3.1 Временные признаки (давность событий относительно 2010 года)\n",
    "df_combined['YearBuildAgo'] = 2010 - df_combined['YearBuilt']\n",
    "df_combined['YearRemodAddAgo'] = 2010 - df_combined['YearRemodAdd']\n",
    "df_combined['GarageYrBltAgo'] = 2010 - df_combined['GarageYrBlt']\n",
    "df_combined['MoSoldAgo'] = 12 - df_combined['MoSold'] + 12 * (2010 - df_combined['YrSold'])\n",
    "\n",
    "# 3.2 Порядковое кодирование (Ordinal Encoding)\n",
    "qual_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "bsmt_fin_map = {'GLQ': 5, 'ALQ': 4, 'BLQ': 3, 'Rec': 3.5, 'LwQ': 2, 'Unf': 1, 'NA': 0}\n",
    "bsmt_exp_map = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0}\n",
    "garage_fin_map = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0}\n",
    "functional_map = {'Typ': 0, 'Min1': 2, 'Min2': 1, 'Mod': 3, 'Maj1': 4, 'Maj2': 5, 'Sev': 6, 'NA': 0}\n",
    "paved_drive_map = {'Y': 0, 'P': 1, 'N': 2}\n",
    "electrical_map = {'SBrkr': 0, 'FuseA': 1, 'FuseF': 2, 'FuseP': 3, 'Mix': 1, 'NA': 1}\n",
    "\n",
    "qual_cols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "for col in qual_cols:\n",
    "    df_combined[col] = df_combined[col].map(qual_map)\n",
    "\n",
    "df_combined['BsmtFinQuality1'] = df_combined['BsmtFinType1'].map(bsmt_fin_map)\n",
    "df_combined['BsmtFinQuality2'] = df_combined['BsmtFinType2'].map(bsmt_fin_map)\n",
    "df_combined['BsmtExposure'] = df_combined['BsmtExposure'].map(bsmt_exp_map)\n",
    "df_combined['GarageFinish'] = df_combined['GarageFinish'].map(garage_fin_map)\n",
    "df_combined['Functional'] = df_combined['Functional'].map(functional_map)\n",
    "df_combined['PavedDrive'] = df_combined['PavedDrive'].map(paved_drive_map)\n",
    "df_combined['Electrical'] = df_combined['Electrical'].map(electrical_map)\n",
    "\n",
    "# 3.3 Создание признаков на основе условий\n",
    "df_combined['Alley_road'] = df_combined['Alley'].map({'NA': 0, 'Grvl': 1, 'Pave': 2})\n",
    "df_combined['LvlLotShape'] = df_combined['LotShape'].map({'Reg': 0, 'IR1': 1, 'IR2': 2, 'IR3': 3})\n",
    "df_combined['LandContourLvl'] = df_combined['LandContour'].apply(lambda x: 0 if x == 'Lvl' else (1 if x == 'Low' else 2))\n",
    "df_combined['Inside'] = (df_combined['LotConfig'] == 'Inside').astype(int)\n",
    "df_combined['Corner'] = (df_combined['LotConfig'] == 'Corner').astype(int)\n",
    "df_combined['CulDSac'] = (df_combined['LotConfig'] == 'CulDSac').astype(int)\n",
    "df_combined['FR'] = df_combined['LotConfig'].apply(lambda x: 2 if x == 'FR3' else (1 if x == 'FR2' else 0))\n",
    "df_combined['LandSlopeLvl'] = df_combined['LandSlope'].map({'Gtl': 0, 'Mod': 1, 'Sev': 2})\n",
    "df_combined['RR'] = ((df_combined['Condition1'].str.contains('RR')) | (df_combined['Condition2'].str.contains('RR'))).astype(int)\n",
    "df_combined['PosObj'] = ((df_combined['Condition1'].str.contains('Pos')) | (df_combined['Condition2'].str.contains('Pos'))).astype(int)\n",
    "df_combined['StreetObj'] = ((df_combined['Condition1'].isin(['Artery', 'Feedr'])) | (df_combined['Condition2'].isin(['Artery', 'Feedr']))).astype(int)\n",
    "df_combined['notFinishFloor'] = ((df_combined['HouseStyle'] == '1.5Unf') | (df_combined['HouseStyle'] == '2.5Unf')).astype(int)\n",
    "df_combined['Split'] = df_combined['HouseStyle'].apply(lambda x: 2 if x == 'SLvl' else (1 if x == 'SFoyer' else 0))\n",
    "df_combined['NumGarage'] = df_combined.apply(lambda row: 2 if row['GarageType'] == '2Types' or row['MiscFeature'] == 'Gar2' else 0 if row['GarageType'] == 'NA' else 1, axis=1)\n",
    "df_combined['Privacy'] = df_combined['Fence'].apply(lambda x: 2 if x == 'GdPrv' else (1 if x in ['MnPrv', 'GdWo'] else 0))\n",
    "df_combined['WoodFence'] = df_combined['Fence'].apply(lambda x: 2 if x == 'GdWo' else (1 if x == 'MnWw' else 0))\n",
    "df_combined['Is_Rec_Room1'] = (df_combined['BsmtFinType1'] == 'Rec').astype(int)\n",
    "df_combined['Is_Rec_Room2'] = (df_combined['BsmtFinType2'] == 'Rec').astype(int)\n",
    "\n",
    "# 3.4 Группировка редких категорий и упрощение признаков\n",
    "df_combined['Neighborhood'] = df_combined['Neighborhood'].apply(lambda x: 'Other' if x in ['Veenker', 'NPkVill', 'Blmngtn', 'Blueste'] else x)\n",
    "df_combined['MSZoning'] = df_combined['MSZoning'].apply(lambda x: 'Other' if x in ['C (all)', 'NA', 'RH'] else x)\n",
    "df_combined['BldgType'] = df_combined['BldgType'].apply(lambda x: 'Other' if x in ['Duplex', 'Twnhs', '2fmCon'] else x)\n",
    "df_combined['RoofStyle'] = df_combined['RoofStyle'].apply(lambda x: 'Other' if x in ['Gambrel', 'Flat', 'Mansard', 'Shed'] else x)\n",
    "df_combined['RoofMatl'] = df_combined['RoofMatl'].apply(lambda x: 'Other' if x in [\"Tar&Grv\", \"ClyTile\", \"Membran\", \"Metal\", \"Roll\", \"WdShngl\", \"WdShake\"] else x)\n",
    "df_combined['MasVnrType'] = df_combined['MasVnrType'].apply(lambda x: 'Other' if x in ['NA', 'BrkCmn'] else x)\n",
    "df_combined['Foundation'] = df_combined['Foundation'].apply(lambda x: 'Other' if x in ['Stone', 'Wood'] else x)\n",
    "df_combined['Heating'] = df_combined['Heating'].apply(lambda x: 'Other' if x in ['GasW', 'Grav', 'Wall', 'OthW', 'Floor'] else x)\n",
    "df_combined['GarageType'] = df_combined['GarageType'].apply(lambda x: 'Other' if x in ['Basment', '2Types', 'CarPort'] else x)\n",
    "df_combined['MiscFeature'] = df_combined['MiscFeature'].apply(lambda x: 'ShedOrOther' if x in ['Gar2', 'Othr', 'TenC', 'Shed'] else x)\n",
    "df_combined['SaleType'] = df_combined['SaleType'].apply(lambda x: 'Other' if x in ['ConLD', 'CWD', 'ConLI', 'ConLw', 'Oth', 'Con', 'NA'] else x)\n",
    "df_combined['SaleCondition'] = df_combined['SaleCondition'].apply(lambda x: 'Other' if x in ['Alloca', 'AdjLand'] else x)\n",
    "\n",
    "# 3.5 One-Hot Encoding для материалов экстерьера\n",
    "main_materials = [\"VinylSd\", \"MetalSd\", \"HdBoard\", \"Wd Sdng\", \"Plywood\", \"CemntBd\", \"BrkFace\", \"WdShing\", \"AsbShng\", \"Stucco\"]\n",
    "for material in main_materials:\n",
    "    df_combined[material] = ((df_combined['Exterior1st'] == material) | (df_combined['Exterior2nd'] == material)).astype(int)\n",
    "df_combined['ExtMat_Other'] = ((~df_combined['Exterior1st'].isin(main_materials)) | (~df_combined['Exterior2nd'].isin(main_materials))).astype(int)\n",
    "\n",
    "\n",
    "# --- ЭТАП 4: ФИНАЛИЗАЦИЯ И РАЗДЕЛЕНИЕ ---\n",
    "\n",
    "# 4.1 Удаляем исходные столбцы, которые были преобразованы или больше не нужны\n",
    "cols_to_drop = [\n",
    "    'Id', 'MSSubClass', 'TotalBsmtSF', 'Street', 'Utilities', 'Alley', 'LotShape',\n",
    "    'LandContour', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType',\n",
    "    'HouseStyle', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'Exterior1st', 'Exterior2nd',\n",
    "    'BsmtFinType1', 'BsmtFinType2', 'GarageYrBlt', 'Fence', 'YrSold', 'MoSold'\n",
    "]\n",
    "df_processed = df_combined.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# 4.2 Преобразуем оставшиеся категориальные столбцы в dummy-переменные\n",
    "df_processed = pd.get_dummies(df_processed, drop_first=True)\n",
    "\n",
    "# 4.3 Преобразуем столбцы типа 'bool' (True/False) в 'int' (1/0)\n",
    "bool_columns = df_processed.select_dtypes(include=['bool']).columns\n",
    "df_processed[bool_columns] = df_processed[bool_columns].astype(int)\n",
    "\n",
    "\n",
    "# --- ЭТАП 5: РАЗДЕЛЕНИЕ НА TRAIN И TEST ---\n",
    "\n",
    "# 5.1 Разделяем обработанный датафрейм обратно на train и test\n",
    "df_train_proc = df_processed.iloc[:train_rows].copy()\n",
    "df_test_proc = df_processed.iloc[train_rows:].copy()\n",
    "\n",
    "# --- КОНЕЦ СКРИПТА ---\n",
    "print(\"Предобработка завершена.\")\n",
    "print(f\"Размер обработанного train датасета: {df_train_proc.shape}\")\n",
    "print(f\"Размер обработанного test датасета:  {df_test_proc.shape}\")\n",
    "print(f\"Целевая переменная 'SalePrice' сохранена отдельно, размер: {train_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "b3b4ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Определен рейтинг признаков по их корреляции с 'SalePrice'.\n",
      "Всего признаков-кандидатов на удаление: 124\n",
      "\n",
      "Топ-15 самых слабых признаков (наименьшая корреляция с ценой):\n",
      " 1. FR                   (Корреляция: 0.0034)\n",
      " 2. Corner               (Корреляция: 0.0041)\n",
      " 3. BsmtFinQuality2      (Корреляция: 0.0061)\n",
      " 4. Foundation_Other     (Корреляция: 0.0083)\n",
      " 5. BsmtFinSF2           (Корреляция: 0.0114)\n",
      " 6. Neighborhood_SawyerW (Корреляция: 0.0146)\n",
      " 7. ExtMat_Other         (Корреляция: 0.0162)\n",
      " 8. BsmtHalfBath         (Корреляция: 0.0168)\n",
      " 9. LandContourLvl       (Корреляция: 0.0175)\n",
      "10. ExterCond            (Корреляция: 0.0189)\n",
      "11. RR                   (Корреляция: 0.0195)\n",
      "12. MiscVal              (Корреляция: 0.0212)\n",
      "13. MoSoldAgo            (Корреляция: 0.0213)\n",
      "14. SaleType_Other       (Корреляция: 0.0223)\n",
      "15. Neighborhood_NWAmes  (Корреляция: 0.0235)\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 3.5: Определение \"слабых\" признаков для отбора\n",
    "\n",
    "# --- 1. Объединяем обработанные признаки с целевой переменной ---\n",
    "# Это нужно для расчета корреляции\n",
    "df_with_target = df_train_proc.copy()\n",
    "df_with_target['SalePrice'] = train_target\n",
    "\n",
    "# --- 2. Рассчитываем корреляцию каждого признака с 'SalePrice' ---\n",
    "correlations = df_with_target.corr()['SalePrice'].abs().sort_values()\n",
    "\n",
    "# --- 3. Исключаем саму целевую переменную из списка ---\n",
    "correlations = correlations.drop('SalePrice')\n",
    "\n",
    "# --- 4. Сохраняем отсортированный список названий признаков ---\n",
    "# Это наши кандидаты на удаление, от самого слабого к более сильному\n",
    "weakest_features_sorted = correlations.index.tolist()\n",
    "\n",
    "print(\"Определен рейтинг признаков по их корреляции с 'SalePrice'.\")\n",
    "print(f\"Всего признаков-кандидатов на удаление: {len(weakest_features_sorted)}\")\n",
    "print(\"\\nТоп-15 самых слабых признаков (наименьшая корреляция с ценой):\")\n",
    "for i, feature in enumerate(weakest_features_sorted[:15]):\n",
    "    print(f\"{i+1:2d}. {feature:<20} (Корреляция: {correlations[feature]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b6bc5",
   "metadata": {},
   "source": [
    "### Ячейка 4: Подготовка данных для обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1fb7214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные разделены на обучающую и валидационную выборки.\n",
      "X_train: (1168, 124), y_train: (1168,)\n",
      "X_val:   (292, 124), y_val:   (292,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train_proc\n",
    "y = train_target\n",
    "\n",
    "# Логарифмируем целевую переменную для стабилизации обучения\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Разделение на обучающую и валидационную выборки\n",
    "X_train, X_val, y_train_log, y_val_log = train_test_split(\n",
    "    X, y_log, \n",
    "    test_size=0.2, \n",
    "    random_state=42 # для воспроизводимости результатов\n",
    ")\n",
    "\n",
    "print(\"Данные разделены на обучающую и валидационную выборки.\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train_log.shape}\")\n",
    "print(f\"X_val:   {X_val.shape}, y_val:   {y_val_log.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c03ff7",
   "metadata": {},
   "source": [
    "### Ячейка 5: Класс-обертка для данных (PyTorch Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "7e5bc35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс HousesDataset и тензоры данных готовы к использованию.\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем данные pandas в формат тензоров PyTorch\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_log.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_log.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(df_test_proc.values, dtype=torch.float32)\n",
    "\n",
    "# Создание кастомного Dataset\n",
    "class HousesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс-обертка для данных о домах.\n",
    "    Позволяет DataLoader'у эффективно работать с нашими тензорами.\n",
    "    \"\"\"\n",
    "    def __init__(self, features, labels=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        # Если метки (labels) не переданы, значит, это тестовый набор\n",
    "        self.is_test = labels is None\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Возвращает общее количество примеров в датасете\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Возвращает один пример (признаки и, если есть, метку) по индексу\n",
    "        if self.is_test:\n",
    "            return self.features[idx]\n",
    "        else:\n",
    "            return self.features[idx], self.labels[idx]\n",
    "\n",
    "print(\"Класс HousesDataset и тензоры данных готовы к использованию.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e2731",
   "metadata": {},
   "source": [
    "### Ячейка 6: Динамическая архитектура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "8911e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Архитектура модели теперь поддерживает выбор функции активации.\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 6: Динамическая архитектура модели (с выбором функции активации)\n",
    "\n",
    "class DynamicRegressionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Нейронная сеть, архитектура и функция активации которой \n",
    "    определяются входными параметрами.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, hidden_layers, dropout_rates, activation_fn_name):\n",
    "        super().__init__()\n",
    "        \n",
    "        # НОВОЕ: Словарь для сопоставления имени функции с классом из PyTorch\n",
    "        activation_functions = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'gelu': nn.GELU(),\n",
    "            'leaky_relu': nn.LeakyReLU(),\n",
    "            'silu': nn.SiLU() # SiLU (или Swish) - еще один мощный вариант\n",
    "        }\n",
    "        \n",
    "        # Получаем объект функции активации по имени\n",
    "        activation_fn = activation_functions.get(activation_fn_name)\n",
    "        if activation_fn is None:\n",
    "            raise ValueError(f\"Неизвестная функция активации: {activation_fn_name}\")\n",
    "\n",
    "        layers = []\n",
    "        input_dim = num_features\n",
    "        \n",
    "        # Динамически создаем скрытые слои\n",
    "        for i, (hidden_dim, dropout_rate) in enumerate(zip(hidden_layers, dropout_rates)):\n",
    "            layers.append(nn.BatchNorm1d(input_dim))\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(activation_fn) # ИЗМЕНЕНИЕ: используем выбранную функцию\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Добавляем выходной слой\n",
    "        layers.append(nn.BatchNorm1d(input_dim))\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"Архитектура модели теперь поддерживает выбор функции активации.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399be448",
   "metadata": {},
   "source": [
    "### Ячейка 7: objective — Сердце эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "5dcc1c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective функция обновлена: теперь она оптимизирует и набор используемых признаков.\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 7: objective — Сердце эксперимента (с отбором признаков)\n",
    "\n",
    "def objective_for_optuna(trial):\n",
    "    \"\"\"\n",
    "    \"Чистая\" функция для одного эксперимента Optuna. \n",
    "    Обучает модель с предложенными гиперпараметрами и возвращает метрику качества.\n",
    "    \"\"\"\n",
    "    # --- 1. Предложение гиперпараметров от Optuna ---\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.004, 0.004, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [64]),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-1, log=True),\n",
    "        'num_hidden_layers': trial.suggest_int('num_hidden_layers', 1, 1),\n",
    "        'activation_fn': trial.suggest_categorical('activation_fn', ['gelu']),\n",
    "        # НОВЫЙ ГИПЕРПАРАМЕТР: Сколько самых слабых признаков отбросить\n",
    "        'num_cols_to_drop': trial.suggest_int('num_cols_to_drop', 0, 90, step=5)\n",
    "    }\n",
    "    \n",
    "    hidden_layers = []\n",
    "    dropout_rates = []\n",
    "    for i in range(params['num_hidden_layers']):\n",
    "        hidden_layers.append(trial.suggest_int(f'n_units_l{i}', 64, 64, step=16))\n",
    "        dropout_rates.append(trial.suggest_float(f'dropout_l{i}', 0.0, 0.5, step=0.1))\n",
    "\n",
    "    # --- 2. Отбор признаков для текущего trial ---\n",
    "    # Получаем список колонок для удаления на основе предложенного Optuna числа\n",
    "    num_to_drop = params['num_cols_to_drop']\n",
    "    cols_to_drop = weakest_features_sorted[:num_to_drop] if num_to_drop > 0 else []\n",
    "    \n",
    "    # Создаем копии данных для этого trial и удаляем колонки\n",
    "    X_train_trial = X_train.drop(columns=cols_to_drop)\n",
    "    X_val_trial = X_val.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # --- 3. Подготовка данных и модели для текущего trial ---\n",
    "    # Преобразуем ИЗМЕНЕННЫЕ данные в тензоры\n",
    "    X_train_tensor_trial = torch.tensor(X_train_trial.values, dtype=torch.float32)\n",
    "    X_val_tensor_trial = torch.tensor(X_val_trial.values, dtype=torch.float32)\n",
    "\n",
    "    train_loader = DataLoader(HousesDataset(X_train_tensor_trial, y_train_tensor), batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(HousesDataset(X_val_tensor_trial, y_val_tensor), batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "    model = DynamicRegressionModel(\n",
    "        # ВАЖНО: количество признаков теперь динамическое\n",
    "        num_features=X_train_trial.shape[1], \n",
    "        hidden_layers=hidden_layers, \n",
    "        dropout_rates=dropout_rates,\n",
    "        activation_fn_name=params['activation_fn']\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.RAdam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=Config.SCHEDULER_FACTOR, patience=Config.SCHEDULER_PATIENCE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # --- 4. Цикл обучения и валидации (без изменений) ---\n",
    "    min_val_loss = float('inf')\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        current_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                current_val_loss += loss.item() * features.size(0)\n",
    "        \n",
    "        epoch_val_loss = np.sqrt(current_val_loss / len(val_loader.dataset))\n",
    "        scheduler.step(epoch_val_loss)\n",
    "\n",
    "        if epoch_val_loss < min_val_loss:\n",
    "            min_val_loss = epoch_val_loss\n",
    "            \n",
    "        if (epoch + 1) % 60 == 0:\n",
    "            trial.report(epoch_val_loss, epoch)\n",
    "            \n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "    return min_val_loss\n",
    "\n",
    "print(\"Objective функция обновлена: теперь она оптимизирует и набор используемых признаков.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "56059e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан кастомный MyTqdmCallback.\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 7.5: Создание нашего собственного, надежного TQDM Callback\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class MyTqdmCallback:\n",
    "    \"\"\"\n",
    "    Кастомный callback для отображения прогресс-бара TQDM для экспериментов Optuna.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_trials):\n",
    "        self.n_trials = n_trials\n",
    "        self.pbar = tqdm(total=n_trials, desc=\"Optuna Optimization\")\n",
    "\n",
    "    def __call__(self, study: \"optuna.study.Study\", trial: \"optuna.trial.FrozenTrial\"):\n",
    "        \"\"\"\n",
    "        Вызывается после каждого завершенного trial.\n",
    "        \"\"\"\n",
    "        self.pbar.update(1)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Закрывает прогресс-бар после завершения исследования.\n",
    "        \"\"\"\n",
    "        self.pbar.close()\n",
    "\n",
    "print(\"Создан кастомный MyTqdmCallback.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "2524185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан кастомный прунер MovingAveragePruner (версия 2.0).\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from optuna.pruners import BasePruner, MedianPruner\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "class MovingAveragePruner(BasePruner):\n",
    "    \"\"\"\n",
    "    Прунер-обертка, который принимает решение на основе скользящего среднего\n",
    "    промежуточных значений, чтобы сгладить шум.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_pruner: BasePruner, window_size: int):\n",
    "        self.base_pruner = base_pruner\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def prune(self, study: \"optuna.study.Study\", trial: \"optuna.trial.FrozenTrial\") -> bool:\n",
    "        intermediate_values = trial.intermediate_values\n",
    "        steps = list(intermediate_values.keys())\n",
    "        \n",
    "        if len(steps) < self.window_size:\n",
    "            return self.base_pruner.prune(study, trial)\n",
    "\n",
    "        last_steps = sorted(steps)[-self.window_size:]\n",
    "        moving_avg = np.mean([intermediate_values[step] for step in last_steps])\n",
    "        \n",
    "        # --- ИСПРАВЛЕНИЕ ---\n",
    "        # Создаем \"двойника\", передавая ему все обязательные поля,\n",
    "        # включая недостающий trial._trial_id.\n",
    "        dummy_trial = optuna.trial.FrozenTrial(\n",
    "            number=trial.number,\n",
    "            state=trial.state,\n",
    "            value=trial.value,\n",
    "            datetime_start=trial.datetime_start,\n",
    "            datetime_complete=trial.datetime_complete,\n",
    "            params=trial.params,\n",
    "            distributions=trial.distributions,\n",
    "            user_attrs=trial.user_attrs,\n",
    "            system_attrs=trial.system_attrs,\n",
    "            intermediate_values={steps[-1]: moving_avg},\n",
    "            trial_id=trial._trial_id  # <-- ВОТ ИСПРАВЛЕНИЕ\n",
    "        )\n",
    "        \n",
    "        return self.base_pruner.prune(study, dummy_trial)\n",
    "\n",
    "print(\"Создан кастомный прунер MovingAveragePruner (версия 2.0).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22cf176",
   "metadata": {},
   "source": [
    "### Ячейка 8: Запуск поиска и логирование только лучшего результата в MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "3a0fb3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:06:03,841] A new study created in RDB with name: house-prices-pytorch-feature-selection2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdda8ac0f5c44daab9f94241b838deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optuna Optimization:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:06:17,803] Trial 0 finished with value: 0.1235937298472017 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0001305253290502967, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 15, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 0 with value: 0.1235937298472017.\n",
      "[I 2025-06-13 12:06:30,051] Trial 1 finished with value: 0.14184337586445528 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0010395536926046066, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 70, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 0 with value: 0.1235937298472017.\n",
      "[I 2025-06-13 12:06:41,230] Trial 2 finished with value: 0.1278337763132837 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0007091402976299218, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 55, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 0 with value: 0.1235937298472017.\n",
      "[I 2025-06-13 12:06:54,374] Trial 3 finished with value: 0.14527974655109951 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.024754381445955445, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 75, 'n_units_l0': 64, 'dropout_l0': 0.5}. Best is trial 0 with value: 0.1235937298472017.\n",
      "[I 2025-06-13 12:07:04,968] Trial 4 finished with value: 0.12441348638307022 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 1.8838235851072174e-05, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 60, 'n_units_l0': 64, 'dropout_l0': 0.1}. Best is trial 0 with value: 0.1235937298472017.\n",
      "[I 2025-06-13 12:07:15,813] Trial 5 finished with value: 0.12107307234992985 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.007936219177699487, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.30000000000000004}. Best is trial 5 with value: 0.12107307234992985.\n",
      "[I 2025-06-13 12:07:27,971] Trial 6 finished with value: 0.1449659906827571 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 2.5221746310873518e-05, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 85, 'n_units_l0': 64, 'dropout_l0': 0.30000000000000004}. Best is trial 5 with value: 0.12107307234992985.\n",
      "[I 2025-06-13 12:07:41,064] Trial 7 finished with value: 0.138905695850516 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.009582575475908293, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 75, 'n_units_l0': 64, 'dropout_l0': 0.1}. Best is trial 5 with value: 0.12107307234992985.\n",
      "[I 2025-06-13 12:07:46,844] Trial 8 pruned. \n",
      "[I 2025-06-13 12:07:53,592] Trial 9 pruned. \n",
      "[I 2025-06-13 12:08:03,803] Trial 10 finished with value: 0.13145727208086005 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.07422708136001648, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.0}. Best is trial 5 with value: 0.12107307234992985.\n",
      "[I 2025-06-13 12:08:12,871] Trial 11 pruned. \n",
      "[I 2025-06-13 12:08:23,202] Trial 12 finished with value: 0.12100475556148961 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.005742691361023825, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:08:36,201] Trial 13 finished with value: 0.12248277601351443 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.006452759439335289, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:08:42,666] Trial 14 pruned. \n",
      "[I 2025-06-13 12:08:48,795] Trial 15 pruned. \n",
      "[I 2025-06-13 12:09:00,057] Trial 16 finished with value: 0.12628513980874628 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.022505898592093416, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:09:06,833] Trial 17 pruned. \n",
      "[I 2025-06-13 12:09:12,970] Trial 18 pruned. \n",
      "[I 2025-06-13 12:09:22,749] Trial 19 finished with value: 0.12554948823911372 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0024462766505191236, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 15, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:09:35,653] Trial 20 finished with value: 0.12828052899493772 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0003978339424503829, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 45, 'n_units_l0': 64, 'dropout_l0': 0.1}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:09:45,955] Trial 21 finished with value: 0.12323296956578103 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.007829251676883012, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:09:52,216] Trial 22 pruned. \n",
      "[I 2025-06-13 12:09:58,375] Trial 23 pruned. \n",
      "[I 2025-06-13 12:10:05,513] Trial 24 pruned. \n",
      "[I 2025-06-13 12:10:11,700] Trial 25 pruned. \n",
      "[I 2025-06-13 12:10:16,323] Trial 26 pruned. \n",
      "[I 2025-06-13 12:10:23,339] Trial 27 pruned. \n",
      "[I 2025-06-13 12:10:29,457] Trial 28 pruned. \n",
      "[I 2025-06-13 12:10:35,900] Trial 29 pruned. \n",
      "[I 2025-06-13 12:10:42,251] Trial 30 pruned. \n",
      "[I 2025-06-13 12:10:53,939] Trial 31 finished with value: 0.12311530066586045 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.007524778820065596, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:11:06,152] Trial 32 finished with value: 0.12185120433395268 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002299075281604971, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:11:10,079] Trial 33 pruned. \n",
      "[I 2025-06-13 12:11:16,382] Trial 34 pruned. \n",
      "[I 2025-06-13 12:11:30,294] Trial 35 finished with value: 0.12259390048194162 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0006547603946764801, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.30000000000000004}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:11:36,270] Trial 36 pruned. \n",
      "[I 2025-06-13 12:11:40,620] Trial 37 pruned. \n",
      "[I 2025-06-13 12:11:46,795] Trial 38 pruned. \n",
      "[I 2025-06-13 12:11:52,772] Trial 39 pruned. \n",
      "[I 2025-06-13 12:11:58,835] Trial 40 pruned. \n",
      "[I 2025-06-13 12:12:09,229] Trial 41 finished with value: 0.12332511206871205 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0008437525691365002, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.30000000000000004}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:12:15,350] Trial 42 pruned. \n",
      "[I 2025-06-13 12:12:29,001] Trial 43 finished with value: 0.1243050673704686 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0002831719096842728, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.30000000000000004}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:12:33,665] Trial 44 pruned. \n",
      "[I 2025-06-13 12:12:40,086] Trial 45 pruned. \n",
      "[I 2025-06-13 12:12:47,117] Trial 46 pruned. \n",
      "[I 2025-06-13 12:12:58,998] Trial 47 finished with value: 0.1281314349255298 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.005115961974972266, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 45, 'n_units_l0': 64, 'dropout_l0': 0.1}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:13:03,037] Trial 48 pruned. \n",
      "[I 2025-06-13 12:13:09,766] Trial 49 pruned. \n",
      "[I 2025-06-13 12:13:16,228] Trial 50 pruned. \n",
      "[I 2025-06-13 12:13:23,589] Trial 51 pruned. \n",
      "[I 2025-06-13 12:13:34,035] Trial 52 finished with value: 0.12361410263135043 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0061107088385328025, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.5}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:13:40,782] Trial 53 pruned. \n",
      "[I 2025-06-13 12:13:47,749] Trial 54 pruned. \n",
      "[I 2025-06-13 12:13:53,573] Trial 55 pruned. \n",
      "[I 2025-06-13 12:13:57,849] Trial 56 pruned. \n",
      "[I 2025-06-13 12:14:10,643] Trial 57 finished with value: 0.12447206258626595 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.019433059494401737, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.5}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:14:16,926] Trial 58 pruned. \n",
      "[I 2025-06-13 12:14:23,644] Trial 59 pruned. \n",
      "[I 2025-06-13 12:14:27,663] Trial 60 pruned. \n",
      "[I 2025-06-13 12:14:34,419] Trial 61 pruned. \n",
      "[I 2025-06-13 12:14:47,086] Trial 62 finished with value: 0.12422206728104505 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.00865729892504701, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:14:53,897] Trial 63 pruned. \n",
      "[I 2025-06-13 12:14:58,721] Trial 64 pruned. \n",
      "[I 2025-06-13 12:15:05,158] Trial 65 pruned. \n",
      "[I 2025-06-13 12:15:11,360] Trial 66 pruned. \n",
      "[I 2025-06-13 12:15:16,878] Trial 67 pruned. \n",
      "[I 2025-06-13 12:15:21,187] Trial 68 pruned. \n",
      "[I 2025-06-13 12:15:27,224] Trial 69 pruned. \n",
      "[I 2025-06-13 12:15:33,696] Trial 70 pruned. \n",
      "[I 2025-06-13 12:15:39,998] Trial 71 pruned. \n",
      "[I 2025-06-13 12:15:47,098] Trial 72 pruned. \n",
      "[I 2025-06-13 12:15:50,815] Trial 73 pruned. \n",
      "[I 2025-06-13 12:16:02,800] Trial 74 finished with value: 0.12176015177510512 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0013947150270656524, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:16:09,448] Trial 75 pruned. \n",
      "[I 2025-06-13 12:16:16,676] Trial 76 pruned. \n",
      "[I 2025-06-13 12:16:21,413] Trial 77 pruned. \n",
      "[I 2025-06-13 12:16:27,988] Trial 78 pruned. \n",
      "[I 2025-06-13 12:16:34,258] Trial 79 pruned. \n",
      "[I 2025-06-13 12:16:41,064] Trial 80 pruned. \n",
      "[I 2025-06-13 12:16:45,862] Trial 81 pruned. \n",
      "[I 2025-06-13 12:16:52,420] Trial 82 pruned. \n",
      "[I 2025-06-13 12:16:58,337] Trial 83 pruned. \n",
      "[I 2025-06-13 12:17:11,490] Trial 84 finished with value: 0.125151451222321 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.011216254446884169, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.30000000000000004}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:17:21,472] Trial 85 finished with value: 0.12456966084792447 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0160562577191179, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:17:28,688] Trial 86 pruned. \n",
      "[I 2025-06-13 12:17:35,179] Trial 87 pruned. \n",
      "[I 2025-06-13 12:17:46,038] Trial 88 finished with value: 0.12122852099081649 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.003508491669554149, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.30000000000000004}. Best is trial 12 with value: 0.12100475556148961.\n",
      "[I 2025-06-13 12:17:58,111] Trial 89 finished with value: 0.1208782205986985 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0033590368243095977, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 89 with value: 0.1208782205986985.\n",
      "[I 2025-06-13 12:18:04,258] Trial 90 pruned. \n",
      "[I 2025-06-13 12:18:08,408] Trial 91 pruned. \n",
      "[I 2025-06-13 12:18:22,209] Trial 92 finished with value: 0.12218601027006123 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.005972626444882897, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 89 with value: 0.1208782205986985.\n",
      "[I 2025-06-13 12:18:36,002] Trial 93 finished with value: 0.12415715205873286 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.005651939862204305, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 20, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 89 with value: 0.1208782205986985.\n",
      "[I 2025-06-13 12:18:46,653] Trial 94 finished with value: 0.12287882174848301 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0035505409921854914, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 89 with value: 0.1208782205986985.\n",
      "[I 2025-06-13 12:18:53,676] Trial 95 pruned. \n",
      "[I 2025-06-13 12:19:00,276] Trial 96 pruned. \n",
      "[I 2025-06-13 12:19:04,413] Trial 97 pruned. \n",
      "[I 2025-06-13 12:19:10,377] Trial 98 pruned. \n",
      "[I 2025-06-13 12:19:22,289] Trial 99 finished with value: 0.11992924150038829 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.001977763278794971, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.4}. Best is trial 99 with value: 0.11992924150038829.\n",
      "[I 2025-06-13 12:19:28,631] Trial 100 pruned. \n",
      "[I 2025-06-13 12:19:33,069] Trial 101 pruned. \n",
      "[I 2025-06-13 12:19:39,429] Trial 102 pruned. \n",
      "[I 2025-06-13 12:19:45,581] Trial 103 pruned. \n",
      "[I 2025-06-13 12:19:52,225] Trial 104 pruned. \n",
      "[I 2025-06-13 12:19:58,582] Trial 105 pruned. \n",
      "[I 2025-06-13 12:20:03,437] Trial 106 pruned. \n",
      "[I 2025-06-13 12:20:09,893] Trial 107 pruned. \n",
      "[I 2025-06-13 12:20:16,554] Trial 108 pruned. \n",
      "[I 2025-06-13 12:20:23,045] Trial 109 pruned. \n",
      "[I 2025-06-13 12:20:33,261] Trial 110 finished with value: 0.11971696359388158 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0026439378201971934, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 110 with value: 0.11971696359388158.\n",
      "[I 2025-06-13 12:20:46,449] Trial 111 finished with value: 0.1218588678323176 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002591519749942297, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 110 with value: 0.11971696359388158.\n",
      "[I 2025-06-13 12:20:57,721] Trial 112 finished with value: 0.12035524956638347 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0027193036584644025, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 110 with value: 0.11971696359388158.\n",
      "[I 2025-06-13 12:21:10,438] Trial 113 finished with value: 0.11700463855647714 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0029006836882291428, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:21:22,961] Trial 114 finished with value: 0.1192081621073879 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0024602703339133133, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:21:28,354] Trial 115 pruned. \n",
      "[I 2025-06-13 12:21:34,743] Trial 116 pruned. \n",
      "[I 2025-06-13 12:21:39,283] Trial 117 pruned. \n",
      "[I 2025-06-13 12:21:45,994] Trial 118 pruned. \n",
      "[I 2025-06-13 12:21:51,733] Trial 119 pruned. \n",
      "[I 2025-06-13 12:21:57,639] Trial 120 pruned. \n",
      "[I 2025-06-13 12:22:10,424] Trial 121 finished with value: 0.12189606225213095 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0028748803341637845, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:22:20,713] Trial 122 finished with value: 0.11799710439412366 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0026473402269204466, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:22:27,021] Trial 123 pruned. \n",
      "[I 2025-06-13 12:22:34,140] Trial 124 pruned. \n",
      "[I 2025-06-13 12:22:41,236] Trial 125 pruned. \n",
      "[I 2025-06-13 12:22:48,081] Trial 126 pruned. \n",
      "[I 2025-06-13 12:22:59,392] Trial 127 finished with value: 0.12008614090544363 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0034267679446654624, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:23:11,823] Trial 128 finished with value: 0.12312922285238218 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0035332782973168135, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:23:21,756] Trial 129 finished with value: 0.12301802447306977 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.004596236026682692, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:23:28,731] Trial 130 pruned. \n",
      "[I 2025-06-13 12:23:41,447] Trial 131 finished with value: 0.11911455308614503 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002246795746018561, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:23:45,532] Trial 132 pruned. \n",
      "[I 2025-06-13 12:23:51,872] Trial 133 pruned. \n",
      "[I 2025-06-13 12:23:58,555] Trial 134 pruned. \n",
      "[I 2025-06-13 12:24:11,090] Trial 135 finished with value: 0.11824296471816852 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.003927732732020258, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:24:21,018] Trial 136 finished with value: 0.12072837288564585 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.004020913975237591, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:24:27,077] Trial 137 pruned. \n",
      "[I 2025-06-13 12:24:39,384] Trial 138 finished with value: 0.12564161196999873 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.00416996454322036, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 20, 'n_units_l0': 64, 'dropout_l0': 0.1}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:24:43,565] Trial 139 pruned. \n",
      "[I 2025-06-13 12:24:49,925] Trial 140 pruned. \n",
      "[I 2025-06-13 12:25:02,963] Trial 141 finished with value: 0.11895954653691905 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002748213587182499, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:25:13,705] Trial 142 finished with value: 0.12063716125904929 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0031301853808999593, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:25:26,141] Trial 143 finished with value: 0.11876723869822105 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002860521526113084, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:25:36,970] Trial 144 finished with value: 0.1188545697728166 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002826345457413232, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:25:50,630] Trial 145 finished with value: 0.1179053652649853 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0027997555921881064, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:25:57,181] Trial 146 pruned. \n",
      "[I 2025-06-13 12:26:08,213] Trial 147 finished with value: 0.11886565097893867 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0027787869919012565, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:26:20,440] Trial 148 finished with value: 0.12219707794313187 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0027024114942700594, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:26:27,381] Trial 149 pruned. \n",
      "[I 2025-06-13 12:26:31,573] Trial 150 pruned. \n",
      "[I 2025-06-13 12:26:44,074] Trial 151 finished with value: 0.11878037760970717 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.004074225654640049, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:26:50,512] Trial 152 pruned. \n",
      "[I 2025-06-13 12:26:57,331] Trial 153 pruned. \n",
      "[I 2025-06-13 12:27:01,900] Trial 154 pruned. \n",
      "[I 2025-06-13 12:27:14,832] Trial 155 finished with value: 0.12347261343199767 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.004599522972673847, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:27:20,941] Trial 156 pruned. \n",
      "[I 2025-06-13 12:27:27,797] Trial 157 pruned. \n",
      "[I 2025-06-13 12:27:37,969] Trial 158 finished with value: 0.11905416868949696 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0027349441153571383, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:27:51,529] Trial 159 finished with value: 0.11978495489742226 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0026081104227586326, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:27:55,376] Trial 160 pruned. \n",
      "[I 2025-06-13 12:28:07,794] Trial 161 finished with value: 0.12096970896687495 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0025596756862260655, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:28:14,017] Trial 162 pruned. \n",
      "[I 2025-06-13 12:28:24,879] Trial 163 finished with value: 0.11769519534744584 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0027015503731097823, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:28:31,606] Trial 164 pruned. \n",
      "[I 2025-06-13 12:28:38,020] Trial 165 pruned. \n",
      "[I 2025-06-13 12:28:50,815] Trial 166 finished with value: 0.1206312154199265 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.005252878494928771, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:28:55,935] Trial 167 pruned. \n",
      "[I 2025-06-13 12:29:02,441] Trial 168 pruned. \n",
      "[I 2025-06-13 12:29:08,959] Trial 169 pruned. \n",
      "[I 2025-06-13 12:29:15,101] Trial 170 pruned. \n",
      "[I 2025-06-13 12:29:25,218] Trial 171 finished with value: 0.11917536196153239 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002630815882599571, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:29:38,261] Trial 172 finished with value: 0.11881293293458084 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002409353321368431, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:29:44,311] Trial 173 pruned. \n",
      "[I 2025-06-13 12:29:48,239] Trial 174 pruned. \n",
      "[I 2025-06-13 12:29:54,128] Trial 175 pruned. \n",
      "[I 2025-06-13 12:30:07,023] Trial 176 finished with value: 0.11808963362250764 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0013635219355680218, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:30:13,360] Trial 177 pruned. \n",
      "[I 2025-06-13 12:30:17,467] Trial 178 pruned. \n",
      "[I 2025-06-13 12:30:29,080] Trial 179 finished with value: 0.12043387560591369 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0030878965225968075, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:30:35,009] Trial 180 pruned. \n",
      "[I 2025-06-13 12:30:44,592] Trial 181 finished with value: 0.1179661864652165 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0024230337250550826, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:30:50,611] Trial 182 pruned. \n",
      "[I 2025-06-13 12:30:56,586] Trial 183 pruned. \n",
      "[I 2025-06-13 12:31:02,915] Trial 184 pruned. \n",
      "[I 2025-06-13 12:31:12,838] Trial 185 finished with value: 0.11889370865165208 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0017110383680498085, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:31:18,765] Trial 186 pruned. \n",
      "[I 2025-06-13 12:31:24,887] Trial 187 pruned. \n",
      "[I 2025-06-13 12:31:30,965] Trial 188 pruned. \n",
      "[I 2025-06-13 12:31:37,008] Trial 189 pruned. \n",
      "[I 2025-06-13 12:31:41,470] Trial 190 pruned. \n",
      "[I 2025-06-13 12:31:47,457] Trial 191 pruned. \n",
      "[I 2025-06-13 12:31:53,183] Trial 192 pruned. \n",
      "[I 2025-06-13 12:31:58,764] Trial 193 pruned. \n",
      "[I 2025-06-13 12:32:08,845] Trial 194 finished with value: 0.12120922423102691 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.003836321771274744, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:32:14,686] Trial 195 pruned. \n",
      "[I 2025-06-13 12:32:27,991] Trial 196 finished with value: 0.12079643730847485 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0025972696273826334, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:32:38,863] Trial 197 finished with value: 0.11938291399119035 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0031610897680943305, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-13 12:32:45,489] Trial 198 pruned. \n",
      "[I 2025-06-13 12:32:52,030] Trial 199 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Оптимизация Optuna завершена!\n",
      "Лучший trial: 113\n",
      "  Значение (min val_rmse): 0.1170\n",
      "  Лучшие гиперпараметры: \n",
      "    learning_rate: 0.004\n",
      "    batch_size: 64\n",
      "    weight_decay: 0.0029006836882291428\n",
      "    num_hidden_layers: 1\n",
      "    activation_fn: gelu\n",
      "    num_cols_to_drop: 30\n",
      "    n_units_l0: 64\n",
      "    dropout_l0: 0.2\n",
      "\n",
      "Запись лучшего эксперимента в MLflow...\n",
      "Переобучение финальной модели на лучших параметрах и с лучшим набором признаков...\n",
      "Найдено, что лучший результат достигается при удалении 30 признаков.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/13 12:33:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/06/13 12:33:04 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0a0+5228986c39.nv25.5) contains a local version label (+5228986c39.nv25.5). MLflow logged a pip requirement for this package as 'torch==2.8.0a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальная модель обучена.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/13 12:33:07 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0a0+5228986c39.nv25.5) contains a local version label (+5228986c39.nv25.5). MLflow logged a pip requirement for this package as 'torch==2.8.0a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/06/13 12:33:07 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    [\n",
      "      70.0,\n",
      "      8400.0,\n",
      "      5.0,\n",
      "      6.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      922.0,\n",
      "      392.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      1314.0,\n",
      "      0.0,\n",
      "      1314.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      5.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      294.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      250.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      53.0,\n",
      "      53.0,\n",
      "      53.0,\n",
      "      3.5,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      59.0,\n",
      "      7837.0,\n",
      "      6.0,\n",
      "      7.0,\n",
      "      0.0,\n",
      "      4.0,\n",
      "      4.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      799.0,\n",
      "      4.0,\n",
      "      0.0,\n",
      "      799.0,\n",
      "      772.0,\n",
      "      1571.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      7.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      2.0,\n",
      "      2.0,\n",
      "      380.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      40.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      17.0,\n",
      "      16.0,\n",
      "      17.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      67.0,\n",
      "      8777.0,\n",
      "      5.0,\n",
      "      7.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      2.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      796.0,\n",
      "      4.0,\n",
      "      1.0,\n",
      "      796.0,\n",
      "      0.0,\n",
      "      796.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      4.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      328.0,\n",
      "      0.0,\n",
      "      164.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      100.0,\n",
      "      60.0,\n",
      "      31.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      60.0,\n",
      "      7200.0,\n",
      "      5.0,\n",
      "      7.0,\n",
      "      252.0,\n",
      "      3.0,\n",
      "      4.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      569.0,\n",
      "      162.0,\n",
      "      5.0,\n",
      "      0.0,\n",
      "      981.0,\n",
      "      787.0,\n",
      "      1768.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      4.0,\n",
      "      7.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      240.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      264.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      73.0,\n",
      "      60.0,\n",
      "      71.0,\n",
      "      4.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      50.0,\n",
      "      5000.0,\n",
      "      5.0,\n",
      "      6.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      218.0,\n",
      "      808.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      1026.0,\n",
      "      665.0,\n",
      "      1691.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      4.0,\n",
      "      6.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      4.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      308.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      242.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      86.0,\n",
      "      60.0,\n",
      "      86.0,\n",
      "      2.0,\n",
      "      2.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ]\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: expected scalar type Double but found Float\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и список удаленных колонок сохранены в MLflow run_id: 7d197180bdc24ed7b17f9635adc369d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'house-prices-regressor-best-fs'.\n",
      "Created version '1' of model 'house-prices-regressor-best-fs'.\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 8: Запуск оптимизации и логирование лучшей модели в MLflow (ФИНАЛЬНАЯ ВЕРСИЯ)\n",
    "\n",
    "# --- 1. Настройка и запуск исследования Optuna ---\n",
    "storage_name = \"sqlite:///optuna_study.db\"\n",
    "study_name = \"house-prices-pytorch-feature-selection2\" # Новое имя для чистоты эксперимента\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "base_pruner = MedianPruner(n_startup_trials=8, n_warmup_steps=100)\n",
    "smart_pruner = MovingAveragePruner(base_pruner=base_pruner, window_size=10)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    direction='minimize',\n",
    "    pruner=smart_pruner,\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "my_callback = MyTqdmCallback(N_TRIALS)\n",
    "try:\n",
    "    study.optimize(objective_for_optuna, n_trials=N_TRIALS, callbacks=[my_callback])\n",
    "finally:\n",
    "    my_callback.close()\n",
    "\n",
    "# --- 2. Вывод результатов Optuna ---\n",
    "print(\"\\nОптимизация Optuna завершена!\")\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params\n",
    "print(f\"Лучший trial: {best_trial.number}\")\n",
    "print(f\"  Значение (min val_rmse): {best_trial.value:.4f}\")\n",
    "print(\"  Лучшие гиперпараметры: \")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# --- 3. Логирование лучшего результата в MLflow ---\n",
    "print(\"\\nЗапись лучшего эксперимента в MLflow...\")\n",
    "with mlflow.start_run(run_name=\"Best_Run_With_Feature_Selection\") as parent_run:\n",
    "    \n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"final_val_rmse\", best_trial.value)\n",
    "    mlflow.set_tag(\"optuna_trial_number\", best_trial.number)\n",
    "    \n",
    "    print(\"Переобучение финальной модели на лучших параметрах и с лучшим набором признаков...\")\n",
    "    \n",
    "    # --- 4. Воссоздание лучших условий ---\n",
    "    # 4.1. Определяем, какие колонки нужно удалить\n",
    "    num_to_drop = best_params['num_cols_to_drop']\n",
    "    cols_to_drop = weakest_features_sorted[:num_to_drop] if num_to_drop > 0 else []\n",
    "    \n",
    "    print(f\"Найдено, что лучший результат достигается при удалении {len(cols_to_drop)} признаков.\")\n",
    "    \n",
    "    # 4.2. Готовим данные с оптимальным набором признаков\n",
    "    X_train_final = X_train.drop(columns=cols_to_drop)\n",
    "    X_train_final_tensor = torch.tensor(X_train_final.values, dtype=torch.float32)\n",
    "    y_train_final_tensor = torch.tensor(y_train_log.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    # 4.3. Собираем параметры для модели\n",
    "    num_hidden_layers = best_params['num_hidden_layers']\n",
    "    hidden_layers = [best_params[f'n_units_l{i}'] for i in range(num_hidden_layers)]\n",
    "    dropout_rates = [best_params[f'dropout_l{i}'] for i in range(num_hidden_layers)]\n",
    "    \n",
    "    # 4.4. Создаем и обучаем финальную модель\n",
    "    final_model = DynamicRegressionModel(\n",
    "        num_features=X_train_final.shape[1], # ВАЖНО: правильное число признаков\n",
    "        hidden_layers=hidden_layers,\n",
    "        dropout_rates=dropout_rates,\n",
    "        activation_fn_name=best_params['activation_fn']\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    train_loader = DataLoader(HousesDataset(X_train_final_tensor, y_train_final_tensor), batch_size=best_params['batch_size'], shuffle=True)\n",
    "    optimizer = torch.optim.RAdam(final_model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Простой цикл обучения без валидации, т.к. мы используем все данные\n",
    "    for epoch in range(EPOCHS):\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = final_model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(\"Финальная модель обучена.\")\n",
    "    \n",
    "    # --- 5. Логирование артефакта-модели в MLflow ---\n",
    "    # Важно, чтобы input_example имел правильную размерность\n",
    "    input_example = X_train_final.head().values\n",
    "    \n",
    "    signature = mlflow.models.infer_signature(input_example)\n",
    "    \n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=final_model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"house-prices-regressor-best-fs\" # fs = feature selection\n",
    "    )\n",
    "    # Логируем список удаленных колонок как артефакт для воспроизводимости\n",
    "    pd.Series(cols_to_drop).to_csv(\"dropped_columns.txt\", index=False, header=False)\n",
    "    mlflow.log_artifact(\"dropped_columns.txt\")\n",
    "    \n",
    "    print(f\"Лучшая модель и список удаленных колонок сохранены в MLflow run_id: {parent_run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4944e82",
   "metadata": {},
   "source": [
    "\n",
    "### Ячейка 9: Загрузка лучшей модели из MLflow и создание Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "3a1f7180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка к созданию submission файла...\n",
      "Загрузка модели из MLflow run_id: 7d197180bdc24ed7b17f9635adc369d8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466a67c1e26e402eab5da6590373a754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd5b3f9aa0846dcb2d28e48860bb91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Применяем к тестовым данным удаление 30 признаков...\n",
      "\n",
      "Submission файл 'submission_house_prices.csv' успешно создан.\n",
      "Первые 5 строк submission файла:\n",
      "     Id      SalePrice\n",
      "0  1461  110943.468750\n",
      "1  1462  153662.750000\n",
      "2  1463  179178.906250\n",
      "3  1464  197095.593750\n",
      "4  1465  214809.921875\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 9: Загрузка лучшей модели из MLflow и создание Submission\n",
    "\n",
    "print(\"Подготовка к созданию submission файла...\")\n",
    "\n",
    "# --- 1. Находим лучший run в MLflow ---\n",
    "# Ищем по новому имени эксперимента, если вы его меняли\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "best_run = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=['metrics.final_val_rmse ASC']\n",
    ").iloc[0]\n",
    "\n",
    "print(f\"Загрузка модели из MLflow run_id: {best_run.run_id}\")\n",
    "\n",
    "# --- 2. Загружаем модель и параметры ---\n",
    "best_model_uri = f\"runs:/{best_run.run_id}/model\"\n",
    "final_model = mlflow.pytorch.load_model(best_model_uri).to(DEVICE)\n",
    "best_params = study.best_trial.params # Можно взять из study или из mlflow\n",
    "\n",
    "# --- 3. Применяем отбор признаков к тестовым данным ---\n",
    "# Определяем, какие колонки были удалены в лучшем trial\n",
    "num_to_drop = best_params['num_cols_to_drop']\n",
    "cols_to_drop = weakest_features_sorted[:num_to_drop] if num_to_drop > 0 else []\n",
    "\n",
    "print(f\"Применяем к тестовым данным удаление {len(cols_to_drop)} признаков...\")\n",
    "\n",
    "# Удаляем те же самые колонки из обработанного тестового датасета\n",
    "df_test_final = df_test_proc.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- 4. Создание предсказаний ---\n",
    "final_model.eval()\n",
    "X_test_tensor = torch.tensor(df_test_final.values, dtype=torch.float32)\n",
    "test_loader = DataLoader(HousesDataset(X_test_tensor), batch_size=256, shuffle=False)\n",
    "\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for features_batch in test_loader:\n",
    "        features_batch = features_batch.to(DEVICE)\n",
    "        outputs = final_model(features_batch)\n",
    "        # Возвращаем к исходному масштабу цен\n",
    "        predicted_prices = torch.expm1(outputs)\n",
    "        all_predictions.extend(predicted_prices.cpu().numpy().flatten().tolist())\n",
    "\n",
    "# --- 5. Создание файла для отправки ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': df_test_original['Id'],\n",
    "    'SalePrice': all_predictions\n",
    "})\n",
    "submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
    "\n",
    "print(f\"\\nSubmission файл '{SUBMISSION_FILE}' успешно создан.\")\n",
    "print(\"Первые 5 строк submission файла:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
