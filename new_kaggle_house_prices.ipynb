{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9bc639",
   "metadata": {},
   "source": [
    "### Ячейка 1: Импорты и глобальные настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все библиотеки импортированы.\n",
      "Обучение будет производиться на устройстве: cuda\n",
      "Optuna version: 4.3.0\n",
      "MLflow version: 3.1.0\n"
     ]
    }
   ],
   "source": [
    "# --- Системные и основные библиотеки ---\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Визуализация ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "# --- Машинное обучение (Scikit-learn) ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Машинное обучение (PyTorch) ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# --- Инструменты для экспериментов ---\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# --- Игнорируем предупреждения для чистоты вывода ---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Константы ---\n",
    "DATA_PATH = \"data\"\n",
    "FILE_TRAIN = os.path.join(DATA_PATH, \"train.csv\")\n",
    "FILE_TEST = os.path.join(DATA_PATH, \"test.csv\")\n",
    "SUBMISSION_FILE = 'submission_house_prices.csv'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Настройки для визуализации ---\n",
    "plt.style.use('ggplot')\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "print(\"Все библиотеки импортированы.\")\n",
    "print(f\"Обучение будет производиться на устройстве: {DEVICE}\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Путь к Python, который использует ядро: /usr/bin/python\n",
      "Версия Optuna, видимая ядру: 4.3.0\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 0: Диагностика окружения\n",
    "import sys\n",
    "import optuna\n",
    "print(f\"Путь к Python, который использует ядро: {sys.executable}\")\n",
    "print(f\"Версия Optuna, видимая ядру: {optuna.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d74704",
   "metadata": {},
   "source": [
    "### Ячейка 2: Конфигурация эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0c8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Конфигурация эксперимента задана.\n",
      "Optuna проведет 200 экспериментов.\n"
     ]
    }
   ],
   "source": [
    "# --- Общие настройки эксперимента ---\n",
    "EXPERIMENT_NAME = \"House Prices - Optuna & MLflow\"\n",
    "N_TRIALS = 200 # Количество экспериментов для Optuna\n",
    "EPOCHS = 240  # Фиксированное количество эпох для каждого эксперимента\n",
    "\n",
    "# --- Базовые параметры (могут быть переопределены Optuna) ---\n",
    "class Config:\n",
    "    # Параметры DataLoader\n",
    "    BATCH_SIZE = 128\n",
    "    \n",
    "    # Параметры оптимизатора\n",
    "    LEARNING_RATE = 0.005\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    \n",
    "    # Параметры планировщика\n",
    "    SCHEDULER_PATIENCE = 30\n",
    "    SCHEDULER_FACTOR = 0.5\n",
    "    \n",
    "    # Параметры архитектуры модели\n",
    "    # Список с количеством нейронов в каждом скрытом слое\n",
    "    HIDDEN_LAYERS = [128, 64] \n",
    "    # Список со значением Dropout для каждого скрытого слоя\n",
    "    DROPOUT_RATES = [0.4, 0.4]\n",
    "\n",
    "print(\"Конфигурация эксперимента задана.\")\n",
    "print(f\"Optuna проведет {N_TRIALS} экспериментов.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b354111",
   "metadata": {},
   "source": [
    "### Ячейка 3: Комплексная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74be5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно загружены.\n",
      "Предобработка завершена.\n",
      "Размер обработанного train датасета: (1460, 124)\n",
      "Размер обработанного test датасета:  (1459, 124)\n",
      "Целевая переменная 'SalePrice' сохранена отдельно, размер: (1460,)\n"
     ]
    }
   ],
   "source": [
    "# --- ЗАГРУЗКА ДАННЫХ ---\n",
    "try:\n",
    "    df_train = pd.read_csv(FILE_TRAIN)\n",
    "    df_test = pd.read_csv(FILE_TEST)\n",
    "    df_test_original = df_test.copy()\n",
    "    print(\"Данные успешно загружены.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Ошибка: Файлы не найдены в директории '{DATA_PATH}'.\")\n",
    "\n",
    "# --- ПОЛНЫЙ ПАЙПЛАЙН ПРЕДОБРАБОТКИ ---\n",
    "\n",
    "# 1. Подготовка\n",
    "df_train_proc = df_train.copy()\n",
    "df_test_proc = df_test.copy()\n",
    "train_target = df_train_proc['SalePrice'].copy()\n",
    "df_train_proc.drop('SalePrice', axis=1, inplace=True)\n",
    "train_rows = len(df_train_proc)\n",
    "df_combined = pd.concat([df_train_proc, df_test_proc], ignore_index=True)\n",
    "\n",
    "\n",
    "# --- ЭТАП 2: БАЗОВАЯ ОЧИСТКА И ЗАПОЛНЕНИЕ ПРОПУСКОВ ---\n",
    "\n",
    "# 2.1 Рассчитываем медианы на ОБЪЕДИНЕННЫХ данных для большей точности\n",
    "lotfrontage_median = df_combined['LotFrontage'].median()\n",
    "garageyrblt_median = df_combined['GarageYrBlt'].median()\n",
    "\n",
    "# 2.2 Заполняем пропуски\n",
    "df_combined['LotFrontage'].fillna(lotfrontage_median, inplace=True)\n",
    "df_combined['GarageYrBlt'].fillna(garageyrblt_median, inplace=True)\n",
    "\n",
    "# 2.3 Заполняем нулями столбцы, где NA означает \"отсутствие\" объекта\n",
    "cols_fill_zero = [\n",
    "    'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "    'GarageCars', 'GarageArea', 'BsmtFullBath', 'BsmtHalfBath'\n",
    "]\n",
    "for col in cols_fill_zero:\n",
    "    df_combined[col].fillna(0, inplace=True)\n",
    "\n",
    "# 2.4 Заполняем пропуски в категориальных признаках строкой 'NA'\n",
    "cat_cols_fill_na = [\n",
    "    'Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "    'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "    'PoolQC', 'Fence', 'MiscFeature', 'MasVnrType', 'Electrical', 'MSZoning',\n",
    "    'Utilities', 'Exterior1st', 'Exterior2nd', 'KitchenQual', 'Functional', 'SaleType'\n",
    "]\n",
    "for col in cat_cols_fill_na:\n",
    "    df_combined[col].fillna('NA', inplace=True)\n",
    "\n",
    "# 2.5 Исправляем опечатки, замеченные при анализе данных\n",
    "df_combined['Exterior2nd'].replace({\"CmentBd\": \"CemntBd\", \"Wd Shng\": \"WdShing\"}, inplace=True)\n",
    "\n",
    "\n",
    "# --- ЭТАП 3: ИНЖИНИРИНГ ПРИЗНАКОВ (FEATURE ENGINEERING) ---\n",
    "\n",
    "# 3.1 Временные признаки (давность событий относительно 2010 года)\n",
    "df_combined['YearBuildAgo'] = 2010 - df_combined['YearBuilt']\n",
    "df_combined['YearRemodAddAgo'] = 2010 - df_combined['YearRemodAdd']\n",
    "df_combined['GarageYrBltAgo'] = 2010 - df_combined['GarageYrBlt']\n",
    "df_combined['MoSoldAgo'] = 12 - df_combined['MoSold'] + 12 * (2010 - df_combined['YrSold'])\n",
    "\n",
    "# 3.2 Порядковое кодирование (Ordinal Encoding)\n",
    "qual_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "bsmt_fin_map = {'GLQ': 5, 'ALQ': 4, 'BLQ': 3, 'Rec': 3.5, 'LwQ': 2, 'Unf': 1, 'NA': 0}\n",
    "bsmt_exp_map = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0}\n",
    "garage_fin_map = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0}\n",
    "functional_map = {'Typ': 0, 'Min1': 2, 'Min2': 1, 'Mod': 3, 'Maj1': 4, 'Maj2': 5, 'Sev': 6, 'NA': 0}\n",
    "paved_drive_map = {'Y': 0, 'P': 1, 'N': 2}\n",
    "electrical_map = {'SBrkr': 0, 'FuseA': 1, 'FuseF': 2, 'FuseP': 3, 'Mix': 1, 'NA': 1}\n",
    "\n",
    "qual_cols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "for col in qual_cols:\n",
    "    df_combined[col] = df_combined[col].map(qual_map)\n",
    "\n",
    "df_combined['BsmtFinQuality1'] = df_combined['BsmtFinType1'].map(bsmt_fin_map)\n",
    "df_combined['BsmtFinQuality2'] = df_combined['BsmtFinType2'].map(bsmt_fin_map)\n",
    "df_combined['BsmtExposure'] = df_combined['BsmtExposure'].map(bsmt_exp_map)\n",
    "df_combined['GarageFinish'] = df_combined['GarageFinish'].map(garage_fin_map)\n",
    "df_combined['Functional'] = df_combined['Functional'].map(functional_map)\n",
    "df_combined['PavedDrive'] = df_combined['PavedDrive'].map(paved_drive_map)\n",
    "df_combined['Electrical'] = df_combined['Electrical'].map(electrical_map)\n",
    "\n",
    "# 3.3 Создание признаков на основе условий\n",
    "df_combined['Alley_road'] = df_combined['Alley'].map({'NA': 0, 'Grvl': 1, 'Pave': 2})\n",
    "df_combined['LvlLotShape'] = df_combined['LotShape'].map({'Reg': 0, 'IR1': 1, 'IR2': 2, 'IR3': 3})\n",
    "df_combined['LandContourLvl'] = df_combined['LandContour'].apply(lambda x: 0 if x == 'Lvl' else (1 if x == 'Low' else 2))\n",
    "df_combined['Inside'] = (df_combined['LotConfig'] == 'Inside').astype(int)\n",
    "df_combined['Corner'] = (df_combined['LotConfig'] == 'Corner').astype(int)\n",
    "df_combined['CulDSac'] = (df_combined['LotConfig'] == 'CulDSac').astype(int)\n",
    "df_combined['FR'] = df_combined['LotConfig'].apply(lambda x: 2 if x == 'FR3' else (1 if x == 'FR2' else 0))\n",
    "df_combined['LandSlopeLvl'] = df_combined['LandSlope'].map({'Gtl': 0, 'Mod': 1, 'Sev': 2})\n",
    "df_combined['RR'] = ((df_combined['Condition1'].str.contains('RR')) | (df_combined['Condition2'].str.contains('RR'))).astype(int)\n",
    "df_combined['PosObj'] = ((df_combined['Condition1'].str.contains('Pos')) | (df_combined['Condition2'].str.contains('Pos'))).astype(int)\n",
    "df_combined['StreetObj'] = ((df_combined['Condition1'].isin(['Artery', 'Feedr'])) | (df_combined['Condition2'].isin(['Artery', 'Feedr']))).astype(int)\n",
    "df_combined['notFinishFloor'] = ((df_combined['HouseStyle'] == '1.5Unf') | (df_combined['HouseStyle'] == '2.5Unf')).astype(int)\n",
    "df_combined['Split'] = df_combined['HouseStyle'].apply(lambda x: 2 if x == 'SLvl' else (1 if x == 'SFoyer' else 0))\n",
    "df_combined['NumGarage'] = df_combined.apply(lambda row: 2 if row['GarageType'] == '2Types' or row['MiscFeature'] == 'Gar2' else 0 if row['GarageType'] == 'NA' else 1, axis=1)\n",
    "df_combined['Privacy'] = df_combined['Fence'].apply(lambda x: 2 if x == 'GdPrv' else (1 if x in ['MnPrv', 'GdWo'] else 0))\n",
    "df_combined['WoodFence'] = df_combined['Fence'].apply(lambda x: 2 if x == 'GdWo' else (1 if x == 'MnWw' else 0))\n",
    "df_combined['Is_Rec_Room1'] = (df_combined['BsmtFinType1'] == 'Rec').astype(int)\n",
    "df_combined['Is_Rec_Room2'] = (df_combined['BsmtFinType2'] == 'Rec').astype(int)\n",
    "\n",
    "# 3.4 Группировка редких категорий и упрощение признаков\n",
    "df_combined['Neighborhood'] = df_combined['Neighborhood'].apply(lambda x: 'Other' if x in ['Veenker', 'NPkVill', 'Blmngtn', 'Blueste'] else x)\n",
    "df_combined['MSZoning'] = df_combined['MSZoning'].apply(lambda x: 'Other' if x in ['C (all)', 'NA', 'RH'] else x)\n",
    "df_combined['BldgType'] = df_combined['BldgType'].apply(lambda x: 'Other' if x in ['Duplex', 'Twnhs', '2fmCon'] else x)\n",
    "df_combined['RoofStyle'] = df_combined['RoofStyle'].apply(lambda x: 'Other' if x in ['Gambrel', 'Flat', 'Mansard', 'Shed'] else x)\n",
    "df_combined['RoofMatl'] = df_combined['RoofMatl'].apply(lambda x: 'Other' if x in [\"Tar&Grv\", \"ClyTile\", \"Membran\", \"Metal\", \"Roll\", \"WdShngl\", \"WdShake\"] else x)\n",
    "df_combined['MasVnrType'] = df_combined['MasVnrType'].apply(lambda x: 'Other' if x in ['NA', 'BrkCmn'] else x)\n",
    "df_combined['Foundation'] = df_combined['Foundation'].apply(lambda x: 'Other' if x in ['Stone', 'Wood'] else x)\n",
    "df_combined['Heating'] = df_combined['Heating'].apply(lambda x: 'Other' if x in ['GasW', 'Grav', 'Wall', 'OthW', 'Floor'] else x)\n",
    "df_combined['GarageType'] = df_combined['GarageType'].apply(lambda x: 'Other' if x in ['Basment', '2Types', 'CarPort'] else x)\n",
    "df_combined['MiscFeature'] = df_combined['MiscFeature'].apply(lambda x: 'ShedOrOther' if x in ['Gar2', 'Othr', 'TenC', 'Shed'] else x)\n",
    "df_combined['SaleType'] = df_combined['SaleType'].apply(lambda x: 'Other' if x in ['ConLD', 'CWD', 'ConLI', 'ConLw', 'Oth', 'Con', 'NA'] else x)\n",
    "df_combined['SaleCondition'] = df_combined['SaleCondition'].apply(lambda x: 'Other' if x in ['Alloca', 'AdjLand'] else x)\n",
    "\n",
    "# 3.5 One-Hot Encoding для материалов экстерьера\n",
    "main_materials = [\"VinylSd\", \"MetalSd\", \"HdBoard\", \"Wd Sdng\", \"Plywood\", \"CemntBd\", \"BrkFace\", \"WdShing\", \"AsbShng\", \"Stucco\"]\n",
    "for material in main_materials:\n",
    "    df_combined[material] = ((df_combined['Exterior1st'] == material) | (df_combined['Exterior2nd'] == material)).astype(int)\n",
    "df_combined['ExtMat_Other'] = ((~df_combined['Exterior1st'].isin(main_materials)) | (~df_combined['Exterior2nd'].isin(main_materials))).astype(int)\n",
    "\n",
    "\n",
    "# --- ЭТАП 4: ФИНАЛИЗАЦИЯ И РАЗДЕЛЕНИЕ ---\n",
    "\n",
    "# 4.1 Удаляем исходные столбцы, которые были преобразованы или больше не нужны\n",
    "cols_to_drop = [\n",
    "    'Id', 'MSSubClass', 'TotalBsmtSF', 'Street', 'Utilities', 'Alley', 'LotShape',\n",
    "    'LandContour', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType',\n",
    "    'HouseStyle', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'Exterior1st', 'Exterior2nd',\n",
    "    'BsmtFinType1', 'BsmtFinType2', 'GarageYrBlt', 'Fence', 'YrSold', 'MoSold'\n",
    "]\n",
    "df_processed = df_combined.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# 4.2 Преобразуем оставшиеся категориальные столбцы в dummy-переменные\n",
    "df_processed = pd.get_dummies(df_processed, drop_first=True)\n",
    "\n",
    "# 4.3 Преобразуем столбцы типа 'bool' (True/False) в 'int' (1/0)\n",
    "bool_columns = df_processed.select_dtypes(include=['bool']).columns\n",
    "df_processed[bool_columns] = df_processed[bool_columns].astype(int)\n",
    "\n",
    "\n",
    "# --- ЭТАП 5: РАЗДЕЛЕНИЕ НА TRAIN И TEST ---\n",
    "\n",
    "# 5.1 Разделяем обработанный датафрейм обратно на train и test\n",
    "df_train_proc = df_processed.iloc[:train_rows].copy()\n",
    "df_test_proc = df_processed.iloc[train_rows:].copy()\n",
    "\n",
    "# --- КОНЕЦ СКРИПТА ---\n",
    "print(\"Предобработка завершена.\")\n",
    "print(f\"Размер обработанного train датасета: {df_train_proc.shape}\")\n",
    "print(f\"Размер обработанного test датасета:  {df_test_proc.shape}\")\n",
    "print(f\"Целевая переменная 'SalePrice' сохранена отдельно, размер: {train_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Определен рейтинг признаков по их корреляции с 'SalePrice'.\n",
      "Всего признаков-кандидатов на удаление: 124\n",
      "\n",
      "Топ-15 самых слабых признаков (наименьшая корреляция с ценой):\n",
      " 1. FR                   (Корреляция: 0.0034)\n",
      " 2. Corner               (Корреляция: 0.0041)\n",
      " 3. BsmtFinQuality2      (Корреляция: 0.0061)\n",
      " 4. Foundation_Other     (Корреляция: 0.0083)\n",
      " 5. BsmtFinSF2           (Корреляция: 0.0114)\n",
      " 6. Neighborhood_SawyerW (Корреляция: 0.0146)\n",
      " 7. ExtMat_Other         (Корреляция: 0.0162)\n",
      " 8. BsmtHalfBath         (Корреляция: 0.0168)\n",
      " 9. LandContourLvl       (Корреляция: 0.0175)\n",
      "10. ExterCond            (Корреляция: 0.0189)\n",
      "11. RR                   (Корреляция: 0.0195)\n",
      "12. MiscVal              (Корреляция: 0.0212)\n",
      "13. MoSoldAgo            (Корреляция: 0.0213)\n",
      "14. SaleType_Other       (Корреляция: 0.0223)\n",
      "15. Neighborhood_NWAmes  (Корреляция: 0.0235)\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 3.5: Определение \"слабых\" признаков для отбора\n",
    "\n",
    "# --- 1. Объединяем обработанные признаки с целевой переменной ---\n",
    "# Это нужно для расчета корреляции\n",
    "df_with_target = df_train_proc.copy()\n",
    "df_with_target['SalePrice'] = train_target\n",
    "\n",
    "# --- 2. Рассчитываем корреляцию каждого признака с 'SalePrice' ---\n",
    "correlations = df_with_target.corr()['SalePrice'].abs().sort_values()\n",
    "\n",
    "# --- 3. Исключаем саму целевую переменную из списка ---\n",
    "correlations = correlations.drop('SalePrice')\n",
    "\n",
    "# --- 4. Сохраняем отсортированный список названий признаков ---\n",
    "# Это наши кандидаты на удаление, от самого слабого к более сильному\n",
    "weakest_features_sorted = correlations.index.tolist()\n",
    "\n",
    "print(\"Определен рейтинг признаков по их корреляции с 'SalePrice'.\")\n",
    "print(f\"Всего признаков-кандидатов на удаление: {len(weakest_features_sorted)}\")\n",
    "print(\"\\nТоп-15 самых слабых признаков (наименьшая корреляция с ценой):\")\n",
    "for i, feature in enumerate(weakest_features_sorted[:15]):\n",
    "    print(f\"{i+1:2d}. {feature:<20} (Корреляция: {correlations[feature]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b6bc5",
   "metadata": {},
   "source": [
    "### Ячейка 4: Подготовка данных для обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные разделены на обучающую и валидационную выборки.\n",
      "X_train: (1168, 124), y_train: (1168,)\n",
      "X_val:   (292, 124), y_val:   (292,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train_proc\n",
    "y = train_target\n",
    "\n",
    "# Логарифмируем целевую переменную для стабилизации обучения\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Разделение на обучающую и валидационную выборки\n",
    "X_train, X_val, y_train_log, y_val_log = train_test_split(\n",
    "    X, y_log, \n",
    "    test_size=0.2, \n",
    "    random_state=42 # для воспроизводимости результатов\n",
    ")\n",
    "\n",
    "print(\"Данные разделены на обучающую и валидационную выборки.\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train_log.shape}\")\n",
    "print(f\"X_val:   {X_val.shape}, y_val:   {y_val_log.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c03ff7",
   "metadata": {},
   "source": [
    "### Ячейка 5: Класс-обертка для данных (PyTorch Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5bc35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс HousesDataset и тензоры данных готовы к использованию.\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем данные pandas в формат тензоров PyTorch\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_log.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_log.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(df_test_proc.values, dtype=torch.float32)\n",
    "\n",
    "# Создание кастомного Dataset\n",
    "class HousesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс-обертка для данных о домах.\n",
    "    Позволяет DataLoader'у эффективно работать с нашими тензорами.\n",
    "    \"\"\"\n",
    "    def __init__(self, features, labels=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        # Если метки (labels) не переданы, значит, это тестовый набор\n",
    "        self.is_test = labels is None\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Возвращает общее количество примеров в датасете\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Возвращает один пример (признаки и, если есть, метку) по индексу\n",
    "        if self.is_test:\n",
    "            return self.features[idx]\n",
    "        else:\n",
    "            return self.features[idx], self.labels[idx]\n",
    "\n",
    "print(\"Класс HousesDataset и тензоры данных готовы к использованию.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e2731",
   "metadata": {},
   "source": [
    "### Ячейка 6: Динамическая архитектура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Архитектура модели теперь поддерживает выбор функции активации.\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 6: Динамическая архитектура модели (с выбором функции активации)\n",
    "\n",
    "class DynamicRegressionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Нейронная сеть, архитектура и функция активации которой \n",
    "    определяются входными параметрами.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, hidden_layers, dropout_rates, activation_fn_name):\n",
    "        super().__init__()\n",
    "        \n",
    "        # НОВОЕ: Словарь для сопоставления имени функции с классом из PyTorch\n",
    "        activation_functions = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'gelu': nn.GELU(),\n",
    "            'leaky_relu': nn.LeakyReLU(),\n",
    "            'silu': nn.SiLU() # SiLU (или Swish) - еще один мощный вариант\n",
    "        }\n",
    "        \n",
    "        # Получаем объект функции активации по имени\n",
    "        activation_fn = activation_functions.get(activation_fn_name)\n",
    "        if activation_fn is None:\n",
    "            raise ValueError(f\"Неизвестная функция активации: {activation_fn_name}\")\n",
    "\n",
    "        layers = []\n",
    "        input_dim = num_features\n",
    "        \n",
    "        # Динамически создаем скрытые слои\n",
    "        for i, (hidden_dim, dropout_rate) in enumerate(zip(hidden_layers, dropout_rates)):\n",
    "            layers.append(nn.BatchNorm1d(input_dim))\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(activation_fn) # ИЗМЕНЕНИЕ: используем выбранную функцию\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Добавляем выходной слой\n",
    "        layers.append(nn.BatchNorm1d(input_dim))\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"Архитектура модели теперь поддерживает выбор функции активации.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399be448",
   "metadata": {},
   "source": [
    "### Ячейка 7: objective — Сердце эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc1c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective функция обновлена: теперь она оптимизирует и набор используемых признаков.\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 7: objective — Сердце эксперимента (с отбором признаков)\n",
    "\n",
    "def objective_for_optuna(trial):\n",
    "    \"\"\"\n",
    "    \"Чистая\" функция для одного эксперимента Optuna. \n",
    "    Обучает модель с предложенными гиперпараметрами и возвращает метрику качества.\n",
    "    \"\"\"\n",
    "    # --- 1. Предложение гиперпараметров от Optuna ---\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.004, 0.004, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [64]),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-1, log=True),\n",
    "        'num_hidden_layers': trial.suggest_int('num_hidden_layers', 1, 1),\n",
    "        'activation_fn': trial.suggest_categorical('activation_fn', ['gelu']),\n",
    "        # НОВЫЙ ГИПЕРПАРАМЕТР: Сколько самых слабых признаков отбросить\n",
    "        'num_cols_to_drop': trial.suggest_int('num_cols_to_drop', 0, 90, step=5)\n",
    "    }\n",
    "    \n",
    "    hidden_layers = []\n",
    "    dropout_rates = []\n",
    "    for i in range(params['num_hidden_layers']):\n",
    "        hidden_layers.append(trial.suggest_int(f'n_units_l{i}', 64, 64, step=16))\n",
    "        dropout_rates.append(trial.suggest_float(f'dropout_l{i}', 0.0, 0.5, step=0.1))\n",
    "\n",
    "    # --- 2. Отбор признаков для текущего trial ---\n",
    "    # Получаем список колонок для удаления на основе предложенного Optuna числа\n",
    "    num_to_drop = params['num_cols_to_drop']\n",
    "    cols_to_drop = weakest_features_sorted[:num_to_drop] if num_to_drop > 0 else []\n",
    "    \n",
    "    # Создаем копии данных для этого trial и удаляем колонки\n",
    "    X_train_trial = X_train.drop(columns=cols_to_drop)\n",
    "    X_val_trial = X_val.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # --- 3. Подготовка данных и модели для текущего trial ---\n",
    "    # Преобразуем ИЗМЕНЕННЫЕ данные в тензоры\n",
    "    X_train_tensor_trial = torch.tensor(X_train_trial.values, dtype=torch.float32)\n",
    "    X_val_tensor_trial = torch.tensor(X_val_trial.values, dtype=torch.float32)\n",
    "\n",
    "    train_loader = DataLoader(HousesDataset(X_train_tensor_trial, y_train_tensor), batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(HousesDataset(X_val_tensor_trial, y_val_tensor), batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "    model = DynamicRegressionModel(\n",
    "        # ВАЖНО: количество признаков теперь динамическое\n",
    "        num_features=X_train_trial.shape[1], \n",
    "        hidden_layers=hidden_layers, \n",
    "        dropout_rates=dropout_rates,\n",
    "        activation_fn_name=params['activation_fn']\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.RAdam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=Config.SCHEDULER_FACTOR, patience=Config.SCHEDULER_PATIENCE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # --- 4. Цикл обучения и валидации (без изменений) ---\n",
    "    min_val_loss = float('inf')\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        current_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                current_val_loss += loss.item() * features.size(0)\n",
    "        \n",
    "        epoch_val_loss = np.sqrt(current_val_loss / len(val_loader.dataset))\n",
    "        scheduler.step(epoch_val_loss)\n",
    "\n",
    "        if epoch_val_loss < min_val_loss:\n",
    "            min_val_loss = epoch_val_loss\n",
    "            \n",
    "        if (epoch + 1) % 60 == 0:\n",
    "            trial.report(epoch_val_loss, epoch)\n",
    "            \n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "    return min_val_loss\n",
    "\n",
    "print(\"Objective функция обновлена: теперь она оптимизирует и набор используемых признаков.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56059e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан кастомный MyTqdmCallback.\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 7.5: Создание нашего собственного, надежного TQDM Callback\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class MyTqdmCallback:\n",
    "    \"\"\"\n",
    "    Кастомный callback для отображения прогресс-бара TQDM для экспериментов Optuna.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_trials):\n",
    "        self.n_trials = n_trials\n",
    "        self.pbar = tqdm(total=n_trials, desc=\"Optuna Optimization\")\n",
    "\n",
    "    def __call__(self, study: \"optuna.study.Study\", trial: \"optuna.trial.FrozenTrial\"):\n",
    "        \"\"\"\n",
    "        Вызывается после каждого завершенного trial.\n",
    "        \"\"\"\n",
    "        self.pbar.update(1)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Закрывает прогресс-бар после завершения исследования.\n",
    "        \"\"\"\n",
    "        self.pbar.close()\n",
    "\n",
    "print(\"Создан кастомный MyTqdmCallback.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан кастомный прунер MovingAveragePruner (версия 2.0).\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from optuna.pruners import BasePruner, MedianPruner\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "class MovingAveragePruner(BasePruner):\n",
    "    \"\"\"\n",
    "    Прунер-обертка, который принимает решение на основе скользящего среднего\n",
    "    промежуточных значений, чтобы сгладить шум.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_pruner: BasePruner, window_size: int):\n",
    "        self.base_pruner = base_pruner\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def prune(self, study: \"optuna.study.Study\", trial: \"optuna.trial.FrozenTrial\") -> bool:\n",
    "        intermediate_values = trial.intermediate_values\n",
    "        steps = list(intermediate_values.keys())\n",
    "        \n",
    "        if len(steps) < self.window_size:\n",
    "            return self.base_pruner.prune(study, trial)\n",
    "\n",
    "        last_steps = sorted(steps)[-self.window_size:]\n",
    "        moving_avg = np.mean([intermediate_values[step] for step in last_steps])\n",
    "        \n",
    "        # --- ИСПРАВЛЕНИЕ ---\n",
    "        # Создаем \"двойника\", передавая ему все обязательные поля,\n",
    "        # включая недостающий trial._trial_id.\n",
    "        dummy_trial = optuna.trial.FrozenTrial(\n",
    "            number=trial.number,\n",
    "            state=trial.state,\n",
    "            value=trial.value,\n",
    "            datetime_start=trial.datetime_start,\n",
    "            datetime_complete=trial.datetime_complete,\n",
    "            params=trial.params,\n",
    "            distributions=trial.distributions,\n",
    "            user_attrs=trial.user_attrs,\n",
    "            system_attrs=trial.system_attrs,\n",
    "            intermediate_values={steps[-1]: moving_avg},\n",
    "            trial_id=trial._trial_id  # <-- ВОТ ИСПРАВЛЕНИЕ\n",
    "        )\n",
    "        \n",
    "        return self.base_pruner.prune(study, dummy_trial)\n",
    "\n",
    "print(\"Создан кастомный прунер MovingAveragePruner (версия 2.0).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22cf176",
   "metadata": {},
   "source": [
    "### Ячейка 8: Запуск поиска и логирование только лучшего результата в MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fb3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 14:26:24,986] Using an existing study with name 'house-prices-pytorch-feature-selection2' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1686adf64bab4c678896b3af50a665ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optuna Optimization:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 14:26:38,958] Trial 200 finished with value: 0.11925028327486914 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0032228681714353133, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:26:46,606] Trial 201 pruned. \n",
      "[I 2025-06-14 14:26:52,474] Trial 202 pruned. \n",
      "[I 2025-06-14 14:26:58,457] Trial 203 pruned. \n",
      "[I 2025-06-14 14:27:04,458] Trial 204 pruned. \n",
      "[I 2025-06-14 14:27:16,715] Trial 205 finished with value: 0.11777805229937853 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0019747956655447397, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:27:21,808] Trial 206 pruned. \n",
      "[I 2025-06-14 14:27:27,616] Trial 207 pruned. \n",
      "[I 2025-06-14 14:27:33,541] Trial 208 pruned. \n",
      "[I 2025-06-14 14:27:46,632] Trial 209 finished with value: 0.12045005690358407 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002168612092964353, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:27:57,914] Trial 210 finished with value: 0.12095665282391939 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0033917642073598296, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:28:02,719] Trial 211 pruned. \n",
      "[I 2025-06-14 14:28:08,330] Trial 212 pruned. \n",
      "[I 2025-06-14 14:28:21,569] Trial 213 finished with value: 0.11906471956961782 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.003510987349260802, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:28:33,032] Trial 214 finished with value: 0.12294794258151756 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.005188282300514442, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:28:38,004] Trial 215 pruned. \n",
      "[I 2025-06-14 14:28:42,977] Trial 216 pruned. \n",
      "[I 2025-06-14 14:28:50,706] Trial 217 pruned. \n",
      "[I 2025-06-14 14:28:56,387] Trial 218 pruned. \n",
      "[I 2025-06-14 14:29:02,168] Trial 219 pruned. \n",
      "[I 2025-06-14 14:29:07,775] Trial 220 pruned. \n",
      "[I 2025-06-14 14:29:19,478] Trial 221 finished with value: 0.11979338957404496 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002676201463448843, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:29:32,216] Trial 222 finished with value: 0.11763546080026224 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002767512880566066, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:29:42,468] Trial 223 finished with value: 0.12096718019837432 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0034967321284925606, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:29:54,933] Trial 224 finished with value: 0.11794082268986085 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0046795948672202995, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:30:06,916] Trial 225 finished with value: 0.1223177078769869 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0064097356333482165, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:30:12,727] Trial 226 pruned. \n",
      "[I 2025-06-14 14:30:17,588] Trial 227 pruned. \n",
      "[I 2025-06-14 14:30:31,416] Trial 228 finished with value: 0.1211969431717772 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.001651115306662417, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:30:37,069] Trial 229 pruned. \n",
      "[I 2025-06-14 14:30:49,001] Trial 230 finished with value: 0.11886081244665121 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002582359797484092, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:30:55,664] Trial 231 pruned. \n",
      "[I 2025-06-14 14:31:03,841] Trial 232 pruned. \n",
      "[I 2025-06-14 14:31:14,111] Trial 233 finished with value: 0.11923549030148144 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0038026877848213528, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:31:19,261] Trial 234 pruned. \n",
      "[I 2025-06-14 14:31:24,379] Trial 235 pruned. \n",
      "[I 2025-06-14 14:31:31,303] Trial 236 pruned. \n",
      "[I 2025-06-14 14:31:36,480] Trial 237 pruned. \n",
      "[I 2025-06-14 14:31:41,862] Trial 238 pruned. \n",
      "[I 2025-06-14 14:31:48,383] Trial 239 pruned. \n",
      "[I 2025-06-14 14:31:54,418] Trial 240 pruned. \n",
      "[I 2025-06-14 14:32:07,547] Trial 241 finished with value: 0.12202169578943073 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0030731170798189893, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:32:13,309] Trial 242 pruned. \n",
      "[I 2025-06-14 14:32:19,074] Trial 243 pruned. \n",
      "[I 2025-06-14 14:32:35,875] Trial 244 pruned. \n",
      "[I 2025-06-14 14:32:46,336] Trial 245 finished with value: 0.11846589254961373 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0030497543271097043, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:32:51,684] Trial 246 pruned. \n",
      "[I 2025-06-14 14:32:56,598] Trial 247 pruned. \n",
      "[I 2025-06-14 14:33:08,926] Trial 248 finished with value: 0.11845269484477638 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0029214764912166903, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:33:14,484] Trial 249 pruned. \n",
      "[I 2025-06-14 14:33:25,502] Trial 250 finished with value: 0.1200666253749817 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0026060912773266886, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:33:30,750] Trial 251 pruned. \n",
      "[I 2025-06-14 14:33:43,158] Trial 252 finished with value: 0.1188300709297414 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002179898034952956, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:33:48,452] Trial 253 pruned. \n",
      "[I 2025-06-14 14:33:53,778] Trial 254 pruned. \n",
      "[I 2025-06-14 14:33:59,396] Trial 255 pruned. \n",
      "[I 2025-06-14 14:34:04,425] Trial 256 pruned. \n",
      "[I 2025-06-14 14:34:17,388] Trial 257 finished with value: 0.12131267884049593 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002934257439762765, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:34:28,552] Trial 258 finished with value: 0.12142765973001257 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0031570059482633277, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:34:33,780] Trial 259 pruned. \n",
      "[I 2025-06-14 14:34:46,529] Trial 260 finished with value: 0.12078345786853105 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002294063762376792, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:34:52,183] Trial 261 pruned. \n",
      "[I 2025-06-14 14:34:57,963] Trial 262 pruned. \n",
      "[I 2025-06-14 14:35:03,519] Trial 263 pruned. \n",
      "[I 2025-06-14 14:35:09,079] Trial 264 pruned. \n",
      "[I 2025-06-14 14:35:21,669] Trial 265 finished with value: 0.1205238301658335 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.005641732500398237, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:35:26,352] Trial 266 pruned. \n",
      "[I 2025-06-14 14:35:31,649] Trial 267 pruned. \n",
      "[I 2025-06-14 14:35:36,769] Trial 268 pruned. \n",
      "[I 2025-06-14 14:35:49,372] Trial 269 finished with value: 0.11760005125183678 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.003370790602134374, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:35:55,371] Trial 270 pruned. \n",
      "[I 2025-06-14 14:36:07,135] Trial 271 finished with value: 0.12023150843009538 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.004709766252591317, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:36:20,846] Trial 272 finished with value: 0.12115179612156927 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.003402660766302645, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:36:31,740] Trial 273 finished with value: 0.12224031519719959 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.00416595674824223, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:36:36,829] Trial 274 pruned. \n",
      "[I 2025-06-14 14:36:41,740] Trial 275 pruned. \n",
      "[I 2025-06-14 14:36:48,983] Trial 276 pruned. \n",
      "[I 2025-06-14 14:36:54,750] Trial 277 pruned. \n",
      "[I 2025-06-14 14:37:00,818] Trial 278 pruned. \n",
      "[I 2025-06-14 14:37:06,633] Trial 279 pruned. \n",
      "[I 2025-06-14 14:37:16,550] Trial 280 finished with value: 0.11709578078677443 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0019943499392747876, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:37:23,536] Trial 281 pruned. \n",
      "[I 2025-06-14 14:37:29,610] Trial 282 pruned. \n",
      "[I 2025-06-14 14:37:34,581] Trial 283 pruned. \n",
      "[I 2025-06-14 14:37:46,425] Trial 284 finished with value: 0.1186364295631193 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002020966742685931, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:37:54,262] Trial 285 pruned. \n",
      "[I 2025-06-14 14:38:04,999] Trial 286 finished with value: 0.12063582748420025 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002278266738213789, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.1}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:38:15,653] Trial 287 finished with value: 0.11723550701535576 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0016308608077372827, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:38:21,027] Trial 288 pruned. \n",
      "[I 2025-06-14 14:38:28,222] Trial 289 pruned. \n",
      "[I 2025-06-14 14:38:39,738] Trial 290 finished with value: 0.12120655394188315 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0008743868959996013, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:38:49,967] Trial 291 finished with value: 0.1233155988023223 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.001687965418787033, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:38:57,279] Trial 292 pruned. \n",
      "[I 2025-06-14 14:39:03,338] Trial 293 pruned. \n",
      "[I 2025-06-14 14:39:14,480] Trial 294 finished with value: 0.11971874074050654 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0018122814308489427, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:39:19,736] Trial 295 pruned. \n",
      "[I 2025-06-14 14:39:25,354] Trial 296 pruned. \n",
      "[I 2025-06-14 14:39:32,375] Trial 297 pruned. \n",
      "[I 2025-06-14 14:39:37,867] Trial 298 pruned. \n",
      "[I 2025-06-14 14:39:43,915] Trial 299 pruned. \n",
      "[I 2025-06-14 14:39:49,938] Trial 300 pruned. \n",
      "[I 2025-06-14 14:39:54,966] Trial 301 pruned. \n",
      "[I 2025-06-14 14:40:02,769] Trial 302 pruned. \n",
      "[I 2025-06-14 14:40:13,881] Trial 303 finished with value: 0.11700912719962314 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0022537410176364653, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 113 with value: 0.11700463855647714.\n",
      "[I 2025-06-14 14:40:18,778] Trial 304 pruned. \n",
      "[I 2025-06-14 14:40:29,148] Trial 305 finished with value: 0.11647633785500136 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0018658713002051225, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:40:36,914] Trial 306 pruned. \n",
      "[I 2025-06-14 14:40:42,968] Trial 307 pruned. \n",
      "[I 2025-06-14 14:40:48,327] Trial 308 pruned. \n",
      "[I 2025-06-14 14:40:54,334] Trial 309 pruned. \n",
      "[I 2025-06-14 14:40:59,236] Trial 310 pruned. \n",
      "[I 2025-06-14 14:41:06,406] Trial 311 pruned. \n",
      "[I 2025-06-14 14:41:12,044] Trial 312 pruned. \n",
      "[I 2025-06-14 14:41:17,157] Trial 313 pruned. \n",
      "[I 2025-06-14 14:41:22,889] Trial 314 pruned. \n",
      "[I 2025-06-14 14:41:28,866] Trial 315 pruned. \n",
      "[I 2025-06-14 14:41:36,644] Trial 316 pruned. \n",
      "[I 2025-06-14 14:41:42,425] Trial 317 pruned. \n",
      "[I 2025-06-14 14:41:48,591] Trial 318 pruned. \n",
      "[I 2025-06-14 14:41:54,523] Trial 319 pruned. \n",
      "[I 2025-06-14 14:42:00,007] Trial 320 pruned. \n",
      "[I 2025-06-14 14:42:12,676] Trial 321 finished with value: 0.11884063794831659 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0019165981714505274, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:42:17,831] Trial 322 pruned. \n",
      "[I 2025-06-14 14:42:28,102] Trial 323 finished with value: 0.12164095023757106 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0020009181754988246, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:42:33,492] Trial 324 pruned. \n",
      "[I 2025-06-14 14:42:41,363] Trial 325 pruned. \n",
      "[I 2025-06-14 14:42:47,156] Trial 326 pruned. \n",
      "[I 2025-06-14 14:42:58,006] Trial 327 finished with value: 0.12114533340485133 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0023749054499065535, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:43:03,942] Trial 328 pruned. \n",
      "[I 2025-06-14 14:43:12,548] Trial 329 pruned. \n",
      "[I 2025-06-14 14:43:17,571] Trial 330 pruned. \n",
      "[I 2025-06-14 14:43:23,055] Trial 331 pruned. \n",
      "[I 2025-06-14 14:43:28,815] Trial 332 pruned. \n",
      "[I 2025-06-14 14:43:34,281] Trial 333 pruned. \n",
      "[I 2025-06-14 14:43:39,347] Trial 334 pruned. \n",
      "[I 2025-06-14 14:43:52,739] Trial 335 finished with value: 0.11967902526706771 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0034140877496891854, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:44:03,342] Trial 336 finished with value: 0.11961520044241948 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002110153507818008, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:44:09,757] Trial 337 pruned. \n",
      "[I 2025-06-14 14:44:16,831] Trial 338 pruned. \n",
      "[I 2025-06-14 14:44:22,121] Trial 339 pruned. \n",
      "[I 2025-06-14 14:44:28,128] Trial 340 pruned. \n",
      "[I 2025-06-14 14:44:39,212] Trial 341 finished with value: 0.11957511214924246 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0017665068532003196, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:44:44,355] Trial 342 pruned. \n",
      "[I 2025-06-14 14:44:51,403] Trial 343 pruned. \n",
      "[I 2025-06-14 14:44:56,340] Trial 344 pruned. \n",
      "[I 2025-06-14 14:45:07,238] Trial 345 finished with value: 0.12054056647249274 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.003664510142450408, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:45:12,673] Trial 346 pruned. \n",
      "[I 2025-06-14 14:45:19,535] Trial 347 pruned. \n",
      "[I 2025-06-14 14:45:24,747] Trial 348 pruned. \n",
      "[I 2025-06-14 14:45:31,036] Trial 349 pruned. \n",
      "[I 2025-06-14 14:45:37,082] Trial 350 pruned. \n",
      "[I 2025-06-14 14:45:42,629] Trial 351 pruned. \n",
      "[I 2025-06-14 14:45:47,852] Trial 352 pruned. \n",
      "[I 2025-06-14 14:45:55,973] Trial 353 pruned. \n",
      "[I 2025-06-14 14:46:01,545] Trial 354 pruned. \n",
      "[I 2025-06-14 14:46:07,161] Trial 355 pruned. \n",
      "[I 2025-06-14 14:46:13,316] Trial 356 pruned. \n",
      "[I 2025-06-14 14:46:18,410] Trial 357 pruned. \n",
      "[I 2025-06-14 14:46:30,159] Trial 358 finished with value: 0.12084871552800412 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.004181914051261404, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:46:35,662] Trial 359 pruned. \n",
      "[I 2025-06-14 14:46:47,477] Trial 360 finished with value: 0.11958556377867191 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0029055605267285295, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:46:54,695] Trial 361 pruned. \n",
      "[I 2025-06-14 14:47:00,559] Trial 362 pruned. \n",
      "[I 2025-06-14 14:47:06,358] Trial 363 pruned. \n",
      "[I 2025-06-14 14:47:11,808] Trial 364 pruned. \n",
      "[I 2025-06-14 14:47:17,099] Trial 365 pruned. \n",
      "[I 2025-06-14 14:47:29,456] Trial 366 finished with value: 0.12198349737071339 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0009354091370387282, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:47:35,044] Trial 367 pruned. \n",
      "[I 2025-06-14 14:47:40,182] Trial 368 pruned. \n",
      "[I 2025-06-14 14:47:45,442] Trial 369 pruned. \n",
      "[I 2025-06-14 14:47:51,330] Trial 370 pruned. \n",
      "[I 2025-06-14 14:48:04,751] Trial 371 finished with value: 0.11831599630438898 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0036656623066005836, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:48:09,642] Trial 372 pruned. \n",
      "[I 2025-06-14 14:48:21,351] Trial 373 finished with value: 0.12067856593115366 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.005789362475113318, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:48:26,651] Trial 374 pruned. \n",
      "[I 2025-06-14 14:48:34,171] Trial 375 pruned. \n",
      "[I 2025-06-14 14:48:39,599] Trial 376 pruned. \n",
      "[I 2025-06-14 14:48:49,835] Trial 377 finished with value: 0.12145088893506575 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0030936134969589526, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:48:55,534] Trial 378 pruned. \n",
      "[I 2025-06-14 14:49:02,911] Trial 379 pruned. \n",
      "[I 2025-06-14 14:49:08,359] Trial 380 pruned. \n",
      "[I 2025-06-14 14:49:19,852] Trial 381 finished with value: 0.11996954766139242 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.002193003906492737, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:49:25,109] Trial 382 pruned. \n",
      "[I 2025-06-14 14:49:30,449] Trial 383 pruned. \n",
      "[I 2025-06-14 14:49:42,454] Trial 384 finished with value: 0.11962504931239931 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0017727304863193038, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 25, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:49:48,051] Trial 385 pruned. \n",
      "[I 2025-06-14 14:49:53,455] Trial 386 pruned. \n",
      "[I 2025-06-14 14:49:59,005] Trial 387 pruned. \n",
      "[I 2025-06-14 14:50:06,144] Trial 388 pruned. \n",
      "[I 2025-06-14 14:50:16,315] Trial 389 finished with value: 0.12172791953477745 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0011984076561615013, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 20, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:50:21,651] Trial 390 pruned. \n",
      "[I 2025-06-14 14:50:27,956] Trial 391 pruned. \n",
      "[I 2025-06-14 14:50:33,990] Trial 392 pruned. \n",
      "[I 2025-06-14 14:50:47,834] Trial 393 finished with value: 0.1237561133912651 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.005405636344358561, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 35, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:50:53,427] Trial 394 pruned. \n",
      "[I 2025-06-14 14:50:58,766] Trial 395 pruned. \n",
      "[I 2025-06-14 14:51:03,756] Trial 396 pruned. \n",
      "[I 2025-06-14 14:51:16,640] Trial 397 finished with value: 0.11837084288146607 and parameters: {'learning_rate': 0.004, 'batch_size': 64, 'weight_decay': 0.0027442995893977827, 'num_hidden_layers': 1, 'activation_fn': 'gelu', 'num_cols_to_drop': 30, 'n_units_l0': 64, 'dropout_l0': 0.2}. Best is trial 305 with value: 0.11647633785500136.\n",
      "[I 2025-06-14 14:51:21,845] Trial 398 pruned. \n",
      "[I 2025-06-14 14:51:27,090] Trial 399 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Оптимизация Optuna завершена!\n",
      "Лучший trial: 305\n",
      "  Значение (min val_rmse): 0.1165\n",
      "  Лучшие гиперпараметры: \n",
      "    learning_rate: 0.004\n",
      "    batch_size: 64\n",
      "    weight_decay: 0.0018658713002051225\n",
      "    num_hidden_layers: 1\n",
      "    activation_fn: gelu\n",
      "    num_cols_to_drop: 30\n",
      "    n_units_l0: 64\n",
      "    dropout_l0: 0.2\n",
      "\n",
      "Запись лучшего эксперимента в MLflow...\n",
      "Переобучение финальной модели на лучших параметрах и с лучшим набором признаков...\n",
      "Найдено, что лучший результат достигается при удалении 30 признаков.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 14:51:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/06/14 14:51:37 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0a0+5228986c39.nv25.5) contains a local version label (+5228986c39.nv25.5). MLflow logged a pip requirement for this package as 'torch==2.8.0a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальная модель обучена.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 14:51:43 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0a0+5228986c39.nv25.5) contains a local version label (+5228986c39.nv25.5). MLflow logged a pip requirement for this package as 'torch==2.8.0a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/06/14 14:51:43 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    [\n",
      "      70.0,\n",
      "      8400.0,\n",
      "      5.0,\n",
      "      6.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      922.0,\n",
      "      392.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      1314.0,\n",
      "      0.0,\n",
      "      1314.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      5.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      294.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      250.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      53.0,\n",
      "      53.0,\n",
      "      53.0,\n",
      "      3.5,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      59.0,\n",
      "      7837.0,\n",
      "      6.0,\n",
      "      7.0,\n",
      "      0.0,\n",
      "      4.0,\n",
      "      4.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      799.0,\n",
      "      4.0,\n",
      "      0.0,\n",
      "      799.0,\n",
      "      772.0,\n",
      "      1571.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      7.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      2.0,\n",
      "      2.0,\n",
      "      380.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      40.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      17.0,\n",
      "      16.0,\n",
      "      17.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      67.0,\n",
      "      8777.0,\n",
      "      5.0,\n",
      "      7.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      2.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      796.0,\n",
      "      4.0,\n",
      "      1.0,\n",
      "      796.0,\n",
      "      0.0,\n",
      "      796.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      4.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      328.0,\n",
      "      0.0,\n",
      "      164.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      100.0,\n",
      "      60.0,\n",
      "      31.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      60.0,\n",
      "      7200.0,\n",
      "      5.0,\n",
      "      7.0,\n",
      "      252.0,\n",
      "      3.0,\n",
      "      4.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      569.0,\n",
      "      162.0,\n",
      "      5.0,\n",
      "      0.0,\n",
      "      981.0,\n",
      "      787.0,\n",
      "      1768.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      4.0,\n",
      "      7.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      240.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      264.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      73.0,\n",
      "      60.0,\n",
      "      71.0,\n",
      "      4.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      50.0,\n",
      "      5000.0,\n",
      "      5.0,\n",
      "      6.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      218.0,\n",
      "      808.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      1026.0,\n",
      "      665.0,\n",
      "      1691.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      0.0,\n",
      "      3.0,\n",
      "      1.0,\n",
      "      4.0,\n",
      "      6.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      4.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      308.0,\n",
      "      3.0,\n",
      "      3.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      242.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      86.0,\n",
      "      60.0,\n",
      "      86.0,\n",
      "      2.0,\n",
      "      2.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ]\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: expected scalar type Double but found Float\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и список удаленных колонок сохранены в MLflow run_id: 8c9a08638c554f37a69870a64fb8d930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'house-prices-regressor-best-fs' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'house-prices-regressor-best-fs'.\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 8: Запуск оптимизации и логирование лучшей модели в MLflow (ФИНАЛЬНАЯ ВЕРСИЯ)\n",
    "\n",
    "# --- 1. Настройка и запуск исследования Optuna ---\n",
    "storage_name = \"sqlite:///optuna_study.db\"\n",
    "study_name = \"house-prices-pytorch-feature-selection2\" # Новое имя для чистоты эксперимента\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "base_pruner = MedianPruner(n_startup_trials=8, n_warmup_steps=100)\n",
    "smart_pruner = MovingAveragePruner(base_pruner=base_pruner, window_size=10)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    direction='minimize',\n",
    "    pruner=smart_pruner,\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "my_callback = MyTqdmCallback(N_TRIALS)\n",
    "try:\n",
    "    study.optimize(objective_for_optuna, n_trials=N_TRIALS, callbacks=[my_callback])\n",
    "finally:\n",
    "    my_callback.close()\n",
    "\n",
    "# --- 2. Вывод результатов Optuna ---\n",
    "print(\"\\nОптимизация Optuna завершена!\")\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params\n",
    "print(f\"Лучший trial: {best_trial.number}\")\n",
    "print(f\"  Значение (min val_rmse): {best_trial.value:.4f}\")\n",
    "print(\"  Лучшие гиперпараметры: \")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# --- 3. Логирование лучшего результата в MLflow ---\n",
    "print(\"\\nЗапись лучшего эксперимента в MLflow...\")\n",
    "with mlflow.start_run(run_name=\"Best_Run_With_Feature_Selection\") as parent_run:\n",
    "    \n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"final_val_rmse\", best_trial.value)\n",
    "    mlflow.set_tag(\"optuna_trial_number\", best_trial.number)\n",
    "    \n",
    "    print(\"Переобучение финальной модели на лучших параметрах и с лучшим набором признаков...\")\n",
    "    \n",
    "    # --- 4. Воссоздание лучших условий ---\n",
    "    # 4.1. Определяем, какие колонки нужно удалить\n",
    "    num_to_drop = best_params['num_cols_to_drop']\n",
    "    cols_to_drop = weakest_features_sorted[:num_to_drop] if num_to_drop > 0 else []\n",
    "    \n",
    "    print(f\"Найдено, что лучший результат достигается при удалении {len(cols_to_drop)} признаков.\")\n",
    "    \n",
    "    # 4.2. Готовим данные с оптимальным набором признаков\n",
    "    X_train_final = X_train.drop(columns=cols_to_drop)\n",
    "    X_train_final_tensor = torch.tensor(X_train_final.values, dtype=torch.float32)\n",
    "    y_train_final_tensor = torch.tensor(y_train_log.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    # 4.3. Собираем параметры для модели\n",
    "    num_hidden_layers = best_params['num_hidden_layers']\n",
    "    hidden_layers = [best_params[f'n_units_l{i}'] for i in range(num_hidden_layers)]\n",
    "    dropout_rates = [best_params[f'dropout_l{i}'] for i in range(num_hidden_layers)]\n",
    "    \n",
    "    # 4.4. Создаем и обучаем финальную модель\n",
    "    final_model = DynamicRegressionModel(\n",
    "        num_features=X_train_final.shape[1], # ВАЖНО: правильное число признаков\n",
    "        hidden_layers=hidden_layers,\n",
    "        dropout_rates=dropout_rates,\n",
    "        activation_fn_name=best_params['activation_fn']\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    train_loader = DataLoader(HousesDataset(X_train_final_tensor, y_train_final_tensor), batch_size=best_params['batch_size'], shuffle=True)\n",
    "    optimizer = torch.optim.RAdam(final_model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Простой цикл обучения без валидации, т.к. мы используем все данные\n",
    "    for epoch in range(EPOCHS):\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = final_model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(\"Финальная модель обучена.\")\n",
    "    \n",
    "    # --- 5. Логирование артефакта-модели в MLflow ---\n",
    "    # Важно, чтобы input_example имел правильную размерность\n",
    "    input_example = X_train_final.head().values\n",
    "    \n",
    "    signature = mlflow.models.infer_signature(input_example)\n",
    "    \n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=final_model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"house-prices-regressor-best-fs\" # fs = feature selection\n",
    "    )\n",
    "    # Логируем список удаленных колонок как артефакт для воспроизводимости\n",
    "    pd.Series(cols_to_drop).to_csv(\"dropped_columns.txt\", index=False, header=False)\n",
    "    mlflow.log_artifact(\"dropped_columns.txt\")\n",
    "    \n",
    "    print(f\"Лучшая модель и список удаленных колонок сохранены в MLflow run_id: {parent_run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4944e82",
   "metadata": {},
   "source": [
    "\n",
    "### Ячейка 9: Загрузка лучшей модели из MLflow и создание Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f7180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка к созданию submission файла...\n",
      "Загрузка модели из MLflow run_id: 8c9a08638c554f37a69870a64fb8d930\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d673f7a3c8044b15911de50589a6a859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480e38fada1c44c38224327e43391aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Применяем к тестовым данным удаление 30 признаков...\n",
      "\n",
      "Submission файл 'submission_house_prices.csv' успешно создан.\n",
      "Первые 5 строк submission файла:\n",
      "     Id      SalePrice\n",
      "0  1461  112257.023438\n",
      "1  1462  162489.828125\n",
      "2  1463  176113.875000\n",
      "3  1464  188928.250000\n",
      "4  1465  198384.156250\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 9: Загрузка лучшей модели из MLflow и создание Submission\n",
    "\n",
    "print(\"Подготовка к созданию submission файла...\")\n",
    "\n",
    "# --- 1. Находим лучший run в MLflow ---\n",
    "# Ищем по новому имени эксперимента, если вы его меняли\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "best_run = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=['metrics.final_val_rmse ASC']\n",
    ").iloc[0]\n",
    "\n",
    "print(f\"Загрузка модели из MLflow run_id: {best_run.run_id}\")\n",
    "\n",
    "# --- 2. Загружаем модель и параметры ---\n",
    "best_model_uri = f\"runs:/{best_run.run_id}/model\"\n",
    "final_model = mlflow.pytorch.load_model(best_model_uri).to(DEVICE)\n",
    "best_params = study.best_trial.params # Можно взять из study или из mlflow\n",
    "\n",
    "# --- 3. Применяем отбор признаков к тестовым данным ---\n",
    "# Определяем, какие колонки были удалены в лучшем trial\n",
    "num_to_drop = best_params['num_cols_to_drop']\n",
    "cols_to_drop = weakest_features_sorted[:num_to_drop] if num_to_drop > 0 else []\n",
    "\n",
    "print(f\"Применяем к тестовым данным удаление {len(cols_to_drop)} признаков...\")\n",
    "\n",
    "# Удаляем те же самые колонки из обработанного тестового датасета\n",
    "df_test_final = df_test_proc.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- 4. Создание предсказаний ---\n",
    "final_model.eval()\n",
    "X_test_tensor = torch.tensor(df_test_final.values, dtype=torch.float32)\n",
    "test_loader = DataLoader(HousesDataset(X_test_tensor), batch_size=256, shuffle=False)\n",
    "\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for features_batch in test_loader:\n",
    "        features_batch = features_batch.to(DEVICE)\n",
    "        outputs = final_model(features_batch)\n",
    "        # Возвращаем к исходному масштабу цен\n",
    "        predicted_prices = torch.expm1(outputs)\n",
    "        all_predictions.extend(predicted_prices.cpu().numpy().flatten().tolist())\n",
    "\n",
    "# --- 5. Создание файла для отправки ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': df_test_original['Id'],\n",
    "    'SalePrice': all_predictions\n",
    "})\n",
    "submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
    "\n",
    "print(f\"\\nSubmission файл '{SUBMISSION_FILE}' успешно создан.\")\n",
    "print(\"Первые 5 строк submission файла:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
